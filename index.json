[{"categories":null,"content":"网络分层结构 计算机网络体系大致分为三种，OSI七层模型、TCP/IP四层模型和五层模型。一般面试的时候考察比较多的是五层模型。 TCP/IP五层模型：应用层、传输层、网络层、数据链路层、物理层。 应用层：为应用程序提供交互服务。在互联网中的应用层协议很多，如域名系统DNS、HTTP协议、SMTP协议等。 传输层：负责向两台主机进程之间的通信提供数据传输服务。传输层的协议主要有传输控制协议TCP和用户数据协议UDP。 网络层：选择合适的路由和交换结点，确保数据及时传送。主要包括IP协议。 数据链路层：在两个相邻节点之间传送数据时，数据链路层将网络层交下来的 IP 数据报组装成帧，在两个相邻节点间的链路上传送帧。 物理层：实现相邻节点间比特流的透明传输，尽可能屏蔽传输介质和物理设备的差异。 ","date":"2022-03-25","objectID":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/:1:0","tags":["计网","八股"],"title":"计算机网络面试题","uri":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"三次握手 假设发送端为客户端，接收端为服务端。开始时客户端和服务端的状态都是CLOSED。 第一次握手：客户端向服务端发起建立连接请求，客户端会随机生成一个起始序列号x，客户端向服务端发送的字段中包含标志位SYN=1，序列号seq=x。第一次握手前客户端的状态为CLOSE，第一次握手后客户端的状态为SYN-SENT。此时服务端的状态为LISTEN。 第二次握手：服务端在收到客户端发来的报文后，会随机生成一个服务端的起始序列号y，然后给客户端回复一段报文，其中包括标志位SYN=1，ACK=1，序列号seq=y，确认号ack=x+1。第二次握手前服务端的状态为LISTEN，第二次握手后服务端的状态为SYN-RCVD，此时客户端的状态为SYN-SENT。（其中SYN=1表示要和客户端建立一个连接，ACK=1表示确认序号有效） 第三次握手：客户端收到服务端发来的报文后，会再向服务端发送报文，其中包含标志位ACK=1，序列号seq=x+1，确认号ack=y+1。第三次握手前客户端的状态为SYN-SENT，第三次握手后客户端和服务端的状态都为ESTABLISHED。此时连接建立完成。 ","date":"2022-03-25","objectID":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/:2:0","tags":["计网","八股"],"title":"计算机网络面试题","uri":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"两次握手可以吗？ 第三次握手主要为了防止已失效的连接请求报文段突然又传输到了服务端，导致产生问题。 比如客户端A发出连接请求，可能因为网络阻塞原因，A没有收到确认报文，于是A再重传一次连接请求。 连接成功，等待数据传输完毕后，就释放了连接。 然后A发出的第一个连接请求等到连接释放以后的某个时间才到达服务端B，此时B误认为A又发出一次新的连接请求，于是就向A发出确认报文段。 如果不采用三次握手，只要B发出确认，就建立新的连接了，此时A不会响应B的确认且不发送数据，则B一直等待A发送数据，浪费资源。 ","date":"2022-03-25","objectID":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/:3:0","tags":["计网","八股"],"title":"计算机网络面试题","uri":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"四次挥手 A的应用进程先向其TCP发出连接释放报文段（FIN=1，seq=u），并停止再发送数据，主动关闭TCP连接，进入FIN-WAIT-1（终止等待1）状态，等待B的确认。 B收到连接释放报文段后即发出确认报文段（ACK=1，ack=u+1，seq=v），B进入CLOSE-WAIT（关闭等待）状态，此时的TCP处于半关闭状态，A到B的连接释放。 A收到B的确认后，进入FIN-WAIT-2（终止等待2）状态，等待B发出的连接释放报文段。 B发送完数据，就会发出连接释放报文段（FIN=1，ACK=1，seq=w，ack=u+1），B进入LAST-ACK（最后确认）状态，等待A的确认。 A收到B的连接释放报文段后，对此发出确认报文段（ACK=1，seq=u+1，ack=w+1），A进入TIME-WAIT（时间等待）状态。此时TCP未释放掉，需要经过时间等待计时器设置的时间2MSL（最大报文段生存时间）后，A才进入CLOSED状态。B收到A发出的确认报文段后关闭连接，若没收到A发出的确认报文段，B就会重传连接释放报文段。 ","date":"2022-03-25","objectID":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/:4:0","tags":["计网","八股"],"title":"计算机网络面试题","uri":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"第四次挥手为什么要等待2MSL？ 保证A发送的最后一个ACK报文段能够到达B。这个ACK报文段有可能丢失，B收不到这个确认报文，就会超时重传连接释放报文段，然后A可以在2MSL时间内收到这个重传的连接释放报文段，接着A重传一次确认，重新启动2MSL计时器，最后A和B都进入到CLOSED状态，若A在TIME-WAIT状态不等待一段时间，而是发送完ACK报文段后立即释放连接，则无法收到B重传的连接释放报文段，所以不会再发送一次确认报文段，B就无法正常进入到CLOSED状态。 防止已失效的连接请求报文段出现在本连接中。A在发送完最后一个ACK报文段后，再经过2MSL，就可以使这个连接所产生的所有报文段都从网络中消失，使下一个新的连接中不会出现旧的连接请求报文段。 ","date":"2022-03-25","objectID":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/:5:0","tags":["计网","八股"],"title":"计算机网络面试题","uri":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"为什么是四次挥手？ 因为当Server端收到Client端的SYN连接请求报文后，可以直接发送SYN+ACK报文。但是在关闭连接时，当Server端收到Client端发出的连接释放报文时，很可能并不会立即关闭SOCKET，所以Server端先回复一个ACK报文，告诉Client端我收到你的连接释放报文了。只有等到Server端所有的报文都发送完了，这时Server端才能发送连接释放报文，之后两边才会真正的断开连接。故需要四次挥手。 ","date":"2022-03-25","objectID":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/:6:0","tags":["计网","八股"],"title":"计算机网络面试题","uri":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"TCP有哪些特点？ TCP是面向连接的运输层协议。 ，每一条TCP连接只能有两个端点。 TCP提供可靠交付的服务。 TCP提供全双工通信。 面向字节流。 ","date":"2022-03-25","objectID":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/:7:0","tags":["计网","八股"],"title":"计算机网络面试题","uri":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"TCP和UDP的区别？ TCP面向连接；UDP是无连接的，即发送数据之前不需要建立连接。 TCP提供可靠的服务；UDP不保证可靠交付。 TCP面向字节流，把数据看成一连串无结构的字节流；UDP是面向报文的。 TCP有拥塞控制；UDP没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如实时视频会议等）。 每一条TCP连接只能是的；UDP支持一对一、一对多、多对一和多对多的通信方式。 TCP首部开销20字节；UDP的首部开销小，只有8个字节。 ","date":"2022-03-25","objectID":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/:8:0","tags":["计网","八股"],"title":"计算机网络面试题","uri":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"HTTP协议的特点？ HTTP允许传输任意类型的数据。传输的类型由Content-Type加以标记。 无状态。对于客户端每次发送的请求，服务器都认为是一个新的请求，上一次会话和下一次会话之间没有联系。 支持客户端/服务器模式。 ","date":"2022-03-25","objectID":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/:9:0","tags":["计网","八股"],"title":"计算机网络面试题","uri":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"HTTP报文格式 HTTP请求由请求行、请求头部、空行和请求体四个部分组成。 请求行：包括请求方法，访问的资源URL，使用的HTTP版本。GET和POST是最常见的HTTP方法，除此以外还包括DELETE、HEAD、OPTIONS、PUT、TRACE。 请求头：格式为“属性名:属性值”，服务端根据请求头获取客户端的信息，主要有cookie、host、connection、accept-language、accept-encoding、user-agent。 请求体：用户的请求数据如用户名，密码等。 请求报文示例： POST /xxx HTTP/1.1 请求行 Accept:image/gif.image/jpeg, 请求头部 Accept-Language:zh-cn Connection:Keep-Alive Host:localhost User-Agent:Mozila/4.0(compatible;MSIE5.01;Window NT5.0) Accept-Encoding:gzip,deflate username=dabin 请求体 HTTP响应也由四个部分组成，分别是：状态行、响应头、空行和响应体。 状态行：协议版本，状态码及状态描述。 响应头：响应头字段主要有connection、content-type、content-encoding、content-length、set-cookie、Last-Modified，、Cache-Control、Expires。 响应体：服务器返回给客户端的内容。 响应报文示例： HTTP/1.1 200 OK Server:Apache Tomcat/5.0.12 Date:Mon,6Oct2003 13:23:42 GMT Content-Length:112 响应体 ","date":"2022-03-25","objectID":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/:10:0","tags":["计网","八股"],"title":"计算机网络面试题","uri":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"HTTP状态码有哪些？ ","date":"2022-03-25","objectID":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/:11:0","tags":["计网","八股"],"title":"计算机网络面试题","uri":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"POST和GET的区别？ GET请求参数通过URL传递，POST的参数放在请求体中。 GET产生一个TCP数据包；POST产生两个TCP数据包。对于GET方式的请求，浏览器会把请求头和请求体一并发送出去；而对于POST，浏览器先发送请求头，服务器响应100 continue，浏览器再发送请求体。 GET请求会被浏览器主动缓存，而POST不会，除非手动设置。 GET请求只能进行url编码，而POST支持多种编码方式。 GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留。 ","date":"2022-03-25","objectID":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/:12:0","tags":["计网","八股"],"title":"计算机网络面试题","uri":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"HTTP长连接和短连接？ HTTP1.0默认使用的是短连接。浏览器和服务器每进行一次HTTP操作，就建立一次连接，任务结束就中断连接。 HTTP/1.1起，默认使用长连接。要使用长连接，客户端和服务器的HTTP首部的Connection都要设置为keep-alive，才能支持长连接。 HTTP长连接，指的是复用TCP连接。多个HTTP请求可以复用同一个TCP连接，这就节省了TCP连接建立和断开的消耗。 ","date":"2022-03-25","objectID":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/:13:0","tags":["计网","八股"],"title":"计算机网络面试题","uri":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"HTTP1.1和 HTTP2.0的区别？ HTTP2.0相比HTTP1.1支持的特性： 新的二进制格式：HTTP1.1 基于文本格式传输数据；HTTP2.0采用二进制格式传输数据，解析更高效。 多路复用：在一个连接里，允许同时发送多个请求或响应，并且这些请求或响应能够并行的传输而不被阻塞，避免 HTTP1.1 出现的”队头堵塞”问题。 头部压缩，HTTP1.1的header带有大量信息，而且每次都要重复发送；HTTP2.0 把header从数据中分离，并封装成头帧和数据帧，使用特定算法压缩头帧，有效减少头信息大小。并且HTTP2.0在客户端和服务器端记录了之前发送的键值对，对于相同的数据，不会重复发送。比如请求a发送了所有的头信息字段，请求b则只需要发送差异数据，这样可以减少冗余数据，降低开销。 服务端推送：HTTP2.0允许服务器向客户端推送资源，无需客户端发送请求到服务器获取。 ","date":"2022-03-25","objectID":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/:14:0","tags":["计网","八股"],"title":"计算机网络面试题","uri":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"HTTPS与HTTP的区别？ HTTP是超文本传输协议，信息是明文传输；HTTPS则是具有安全性的ssl加密传输协议。 HTTP和HTTPS用的端口不一样，HTTP端口是80，HTTPS是443。 HTTPS协议需要到CA机构申请证书，一般需要一定的费用。 HTTP运行在TCP协议之上；HTTPS运行在SSL协议之上，SSL运行在TCP协议之上。 ","date":"2022-03-25","objectID":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/:15:0","tags":["计网","八股"],"title":"计算机网络面试题","uri":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"什么是数字证书？ 服务端可以向证书颁发机构CA申请证书，以避免中间人攻击（防止证书被篡改）。证书包含三部分内容：证书内容、证书签名算法和签名，签名是为了验证身份。 服务端把证书传输给浏览器，浏览器从证书里取公钥。证书可以证明该公钥对应本网站。 数字签名的制作过程： CA使用证书签名算法对证书内容进行hash运算。 对hash后的值用CA的私钥加密，得到数字签名。 浏览器验证过程： 获取证书，得到证书内容、证书签名算法和数字签名。 用CA机构的公钥对数字签名解密（由于是浏览器信任的机构，所以浏览器会保存它的公钥）。 用证书里的签名算法对证书内容进行hash运算。 比较解密后的数字签名和对证书内容做hash运算后得到的哈希值，相等则表明证书可信。 ","date":"2022-03-25","objectID":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/:16:0","tags":["计网","八股"],"title":"计算机网络面试题","uri":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"HTTPS原理 首先是TCP三次握手，然后客户端发起一个HTTPS连接建立请求，客户端先发一个Client Hello的包，然后服务端响应Server Hello，接着再给客户端发送它的证书，然后双方经过密钥交换，最后使用交换的密钥加解密数据。 协商加密算法 。在Client Hello里面客户端会告知服务端自己当前的一些信息，包括客户端要使用的TLS版本，支持的加密算法，要访问的域名，给服务端生成的一个随机数（Nonce）等。需要提前告知服务器想要访问的域名以便服务器发送相应的域名的证书过来。 服务端响应Server Hello，告诉客户端服务端选中的加密算法。 接着服务端给客户端发来了2个证书。第二个证书是第一个证书的签发机构（CA）的证书。 客户端使用证书的认证机构CA公开发布的RSA公钥对该证书进行验证，下图表明证书认证成功。 验证通过之后，浏览器和服务器通过密钥交换算法产生共享的对称密钥。 开始传输数据，使用同一个对称密钥来加解密。 ","date":"2022-03-25","objectID":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/:17:0","tags":["计网","八股"],"title":"计算机网络面试题","uri":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"DNS 的解析过程？ 浏览器搜索自己的DNS缓存 若没有，则搜索操作系统中的DNS缓存和hosts文件 若没有，则操作系统将域名发送至本地域名服务器，本地域名服务器查询自己的DNS缓存，查找成功则返回结果，否则依次向根域名服务器、顶级域名服务器、权限域名服务器发起查询请求，最终返回IP地址给本地域名服务器 本地域名服务器将得到的IP地址返回给操作系统，同时自己也将IP地址缓存起来 操作系统将 IP 地址返回给浏览器，同时自己也将IP地址缓存起来 浏览器得到域名对应的IP地址 ","date":"2022-03-25","objectID":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/:18:0","tags":["计网","八股"],"title":"计算机网络面试题","uri":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"浏览器中输入URL返回页面过程？ 解析域名，找到主机 IP。 浏览器利用 IP 直接与网站主机通信，三次握手，建立 TCP 连接。浏览器会以一个随机端口向服务端的 web 程序 80 端口发起 TCP 的连接。 建立 TCP 连接后，浏览器向主机发起一个HTTP请求。 服务器响应请求，返回响应数据。 浏览器解析响应内容，进行渲染，呈现给用户。 ","date":"2022-03-25","objectID":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/:19:0","tags":["计网","八股"],"title":"计算机网络面试题","uri":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"什么是cookie和session？ 由于HTTP协议是无状态的协议，需要用某种机制来识具体的用户身份，用来跟踪用户的整个会话。常用的会话跟踪技术是cookie与session。 cookie就是由服务器发给客户端的特殊信息，而这些信息以文本文件的方式存放在客户端，然后客户端每次向服务器发送请求的时候都会带上这些特殊的信息。说得更具体一些：当用户使用浏览器访问一个支持cookie的网站的时候，用户会提供包括用户名在内的个人信息并且提交至服务器；接着，服务器在向客户端回传相应的超文本的同时也会发回这些个人信息，当然这些信息并不是存放在HTTP响应体中的，而是存放于HTTP响应头；当客户端浏览器接收到来自服务器的响应之后，浏览器会将这些信息存放在一个统一的位置。 自此，客户端再向服务器发送请求的时候，都会把相应的cookie存放在HTTP请求头再次发回至服务器。服务器在接收到来自客户端浏览器的请求之后，就能够通过分析存放于请求头的cookie得到客户端特有的信息，从而动态生成与该客户端相对应的内容。网站的登录界面中“请记住我”这样的选项，就是通过cookie实现的。 cookie工作流程： servlet创建cookie，保存少量数据，发送给浏览器。 浏览器获得服务器发送的cookie数据，将自动的保存到浏览器端。 下次访问时，浏览器将自动携带cookie数据发送给服务器。 session原理：首先浏览器请求服务器访问web站点时，服务器首先会检查这个客户端请求是否已经包含了一个session标识（sessionid），如果已经包含了一个sessionid则说明以前已经为此客户端创建过session，服务器就按照sessionid把这个session检索出来使用，如果客户端请求不包含session id，则服务器为此客户端创建一个session，并且生成一个与此session相关联的独一无二的sessionid存放到cookie中，这个sessionid将在本次响应中返回到客户端保存，这样在交互的过程中，浏览器端每次请求时，都会带着这个sessionid，服务器根据这个sessionid就可以找得到对应的session。以此来达到共享数据的目的。 这里需要注意的是，session不会随着浏览器的关闭而死亡，而是等待超时时间。 ","date":"2022-03-25","objectID":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/:20:0","tags":["计网","八股"],"title":"计算机网络面试题","uri":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"Cookie和Session的区别？ 作用范围不同，Cookie 保存在客户端，Session 保存在服务器端。 有效期不同，Cookie 可设置为长时间保持，比如我们经常使用的默认登录功能，Session 一般失效时间较短，客户端关闭或者 Session 超时都会失效。 隐私策略不同，Cookie 存储在客户端，容易被窃取；Session 存储在服务端，安全性相对 Cookie 要好一些。 存储大小不同， 单个 Cookie 保存的数据不能超过 4K；对于 Session 来说存储没有上限，但出于对服务器的性能考虑，Session 内不要存放过多的数据，并且需要设置 Session 删除机制。 ","date":"2022-03-25","objectID":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/:21:0","tags":["计网","八股"],"title":"计算机网络面试题","uri":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"什么是对称加密和非对称加密？ 对称加密：通信双方使用相同的密钥进行加密。特点是加密速度快，但是缺点是密钥泄露会导致密文数据被破解。常见的对称加密有AES和DES算法。 非对称加密：它需要生成两个密钥，公钥和私钥。公钥是公开的，任何人都可以获得，而私钥是私人保管的。公钥负责加密，私钥负责解密；或者私钥负责加密，公钥负责解密。这种加密算法安全性更高，但是计算量相比对称加密大很多，加密和解密都很慢。常见的非对称算法有RSA和DSA。 ","date":"2022-03-25","objectID":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/:22:0","tags":["计网","八股"],"title":"计算机网络面试题","uri":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"滑动窗口机制 TCP 利用滑动窗口实现流量控制。流量控制是为了控制发送方发送速率，保证接收方来得及接收。 TCP会话的双方都各自维护一个发送窗口和一个接收窗口。接收窗口大小取决于应用、系统、硬件的限制。发送窗口则取决于对端通告的接收窗口。接收方发送的确认报文中的window字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将接收方的确认报文window字段设置为 0，则发送方不能发送数据。 TCP头包含window字段，16bit位，它代表的是窗口的字节容量，最大为65535。这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。接收窗口的大小是约等于发送窗口的大小。 ","date":"2022-03-25","objectID":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/:23:0","tags":["计网","八股"],"title":"计算机网络面试题","uri":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"详细讲一下拥塞控制？ 防止过多的数据注入到网络中。 几种拥塞控制方法：慢开始( slow-start )、拥塞避免( congestion avoidance )、快重传( fast retransmit )和快恢复( fast recovery )。 ","date":"2022-03-25","objectID":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/:24:0","tags":["计网","八股"],"title":"计算机网络面试题","uri":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"慢开始 把拥塞窗口 cwnd 设置为一个最大报文段MSS的数值。而在每收到一个对新的报文段的确认后，把拥塞窗口增加至多一个MSS的数值。每经过一个传输轮次，拥塞窗口 cwnd 就加倍。 为了防止拥塞窗口cwnd增长过大引起网络拥塞，还需要设置一个慢开始门限ssthresh状态变量。 当 cwnd \u003c ssthresh 时，使用慢开始算法。 当 cwnd \u003e ssthresh 时，停止使用慢开始算法而改用拥塞避免算法。 当 cwnd = ssthresh 时，既可使用慢开始算法，也可使用拥塞控制避免算法。 ","date":"2022-03-25","objectID":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/:24:1","tags":["计网","八股"],"title":"计算机网络面试题","uri":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"拥塞避免 让拥塞窗口cwnd缓慢地增大，每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1，而不是加倍。这样拥塞窗口cwnd按线性规律缓慢增长。 无论在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有收到确认），就要把慢开始门限ssthresh设置为出现拥塞时的发送 方窗口值的一半（但不能小于2）。然后把拥塞窗口cwnd重新设置为1，执行慢开始算法。这样做的目的就是要迅速减少主机发送到网络中的分组数，使得发生 拥塞的路由器有足够时间把队列中积压的分组处理完毕。 ","date":"2022-03-25","objectID":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/:24:2","tags":["计网","八股"],"title":"计算机网络面试题","uri":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"快重传 有时个别报文段会在网络中丢失，但实际上网络并未发生拥塞。如果发送方迟迟收不到确认，就会产生超时，就会误认为网络发生了拥塞。这就导致发送方错误地启动慢开始，把拥塞窗口cwnd又设置为1，因而降低了传输效率。 快重传算法可以避免这个问题。快重传算法首先要求接收方每收到一个失序的报文段后就立即发出重复确认，使发送方及早知道有报文段没有到达对方。 发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待重传计时器到期。由于发送方尽早重传未被确认的报文段，因此采用快重传后可以使整个网络吞吐量提高约20%。 ","date":"2022-03-25","objectID":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/:24:3","tags":["计网","八股"],"title":"计算机网络面试题","uri":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"快恢复 当发送方连续收到三个重复确认，就会把慢开始门限ssthresh减半，接着把cwnd值设置为慢开始门限ssthresh减半后的数值，然后开始执行拥塞避免算法，使拥塞窗口缓慢地线性增大。 在采用快恢复算法时，慢开始算法只是在TCP连接建立时和网络出现超时时才使用。 采用这样的拥塞控制方法使得TCP的性能有明显的改进。 ","date":"2022-03-25","objectID":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/:24:4","tags":["计网","八股"],"title":"计算机网络面试题","uri":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"ARP协议 ARP解决了同一个局域网上的主机和路由器IP和MAC地址的解析。 每台主机都会在自己的ARP缓冲区中建立一个ARP列表，以表示IP地址和MAC地址的对应关系。 当源主机需要将一个数据包要发送到目的主机时，会首先检查自己 ARP列表中是否存在该 IP地址对应的MAC地址，如果有，就直接将数据包发送到这个MAC地址；如果没有，就向本地网段发起一个ARP请求的广播包，查询此目的主机对应的MAC地址。此ARP请求数据包里包括源主机的IP地址、硬件地址、以及目的主机的IP地址。 网络中所有的主机收到这个ARP请求后，会检查数据包中的目的IP是否和自己的IP地址一致。如果不相同就忽略此数据包；如果相同，该主机首先将发送端的MAC地址和IP地址添加到自己的ARP列表中，如果ARP表中已经存在该IP的信息，则将其覆盖，然后给源主机发送一个 ARP响应数据包，告诉对方自己是它需要查找的MAC地址。 源主机收到这个ARP响应数据包后，将得到的目的主机的IP地址和MAC地址添加到自己的ARP列表中，并利用此信息开始数据的传输。 如果源主机一直没有收到ARP响应数据包，表示ARP查询失败。 ref https://www.nowcoder.com/discuss/870064 ","date":"2022-03-25","objectID":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/:25:0","tags":["计网","八股"],"title":"计算机网络面试题","uri":"/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"简介 腾讯云函数是一种serverless解决方案，使用云函数你就不需要关注运维，扩容，日志也是自动收集，非常的方便 ","date":"2022-03-24","objectID":"/posts/cloud/%E8%85%BE%E4%BA%91%E4%BA%91%E5%87%BD%E6%95%B0%E9%83%A8%E7%BD%B2%E5%8F%8A%E5%9D%91/:1:0","tags":["cloud","白嫖"],"title":"腾云云函数部署及坑","uri":"/posts/cloud/%E8%85%BE%E4%BA%91%E4%BA%91%E5%87%BD%E6%95%B0%E9%83%A8%E7%BD%B2%E5%8F%8A%E5%9D%91/"},{"categories":null,"content":"触发方式 定时触发 通过编写corntab进行触发，比如签到，你可以早上8点开始到下午5点，每隔5分钟就看看有没有签到 web方式触发 类似于http服务器，不同的是正常http服务器是一直后台运行，但是这个是只有请求来了才运行，请求完成后就自动销毁，当然，也不一定销毁，比如当你请求量很大的时候，他会一直保持后台运行 ","date":"2022-03-24","objectID":"/posts/cloud/%E8%85%BE%E4%BA%91%E4%BA%91%E5%87%BD%E6%95%B0%E9%83%A8%E7%BD%B2%E5%8F%8A%E5%9D%91/:1:1","tags":["cloud","白嫖"],"title":"腾云云函数部署及坑","uri":"/posts/cloud/%E8%85%BE%E4%BA%91%E4%BA%91%E5%87%BD%E6%95%B0%E9%83%A8%E7%BD%B2%E5%8F%8A%E5%9D%91/"},{"categories":null,"content":"使用语言 我这里使用的是go语言，要先编译成linux x64的可执行文件后，在压缩上传 ","date":"2022-03-24","objectID":"/posts/cloud/%E8%85%BE%E4%BA%91%E4%BA%91%E5%87%BD%E6%95%B0%E9%83%A8%E7%BD%B2%E5%8F%8A%E5%9D%91/:2:0","tags":["cloud","白嫖"],"title":"腾云云函数部署及坑","uri":"/posts/cloud/%E8%85%BE%E4%BA%91%E4%BA%91%E5%87%BD%E6%95%B0%E9%83%A8%E7%BD%B2%E5%8F%8A%E5%9D%91/"},{"categories":null,"content":"scf_bootstrap 所有云函数都最好在根目录下面有一个 scf_bootstrap 文件，这里面的内容主要是如何启动这个应用如 #!/bin/bash ./httpserver 值得注意的是这里有个坑，这个scf_bootstrap必须要使用 lf 换行符，别的都不行，如果使用别的，执行的时候就会报错如，非常的shit { \"errorCode\": -1, \"errorMessage\": \"Failed to initialize the container. Please confirm that the container can be started locally.\", \"statusCode\": 405 } 一定使用LF换行符 一定使用LF换行符 一定使用LF换行符 ","date":"2022-03-24","objectID":"/posts/cloud/%E8%85%BE%E4%BA%91%E4%BA%91%E5%87%BD%E6%95%B0%E9%83%A8%E7%BD%B2%E5%8F%8A%E5%9D%91/:3:0","tags":["cloud","白嫖"],"title":"腾云云函数部署及坑","uri":"/posts/cloud/%E8%85%BE%E4%BA%91%E4%BA%91%E5%87%BD%E6%95%B0%E9%83%A8%E7%BD%B2%E5%8F%8A%E5%9D%91/"},{"categories":null,"content":"部署 部署也是一言难尽，使用正常的压缩软件如7z进行压缩（windows） 部署，就会出现这个 /var/user/scf_bootstrap: line 3: ./httpserver: Permission denied 为啥呢，因为你使用的是windows进行压缩，和在linux下压缩的是不一样的 windows linux 可以看到windows的属性是A，猜测在解压以后就没有访问权限了 所以 必须使用linux进行压缩 必须使用linux进行压缩 必须使用linux进行压缩 ","date":"2022-03-24","objectID":"/posts/cloud/%E8%85%BE%E4%BA%91%E4%BA%91%E5%87%BD%E6%95%B0%E9%83%A8%E7%BD%B2%E5%8F%8A%E5%9D%91/:4:0","tags":["cloud","白嫖"],"title":"腾云云函数部署及坑","uri":"/posts/cloud/%E8%85%BE%E4%BA%91%E4%BA%91%E5%87%BD%E6%95%B0%E9%83%A8%E7%BD%B2%E5%8F%8A%E5%9D%91/"},{"categories":null,"content":"结语 虽然腾讯云函数有各种各样的坑，免费额度也少，但最后部署成功还是挺开心的，也希望大家都能早日部署成功 ","date":"2022-03-24","objectID":"/posts/cloud/%E8%85%BE%E4%BA%91%E4%BA%91%E5%87%BD%E6%95%B0%E9%83%A8%E7%BD%B2%E5%8F%8A%E5%9D%91/:5:0","tags":["cloud","白嫖"],"title":"腾云云函数部署及坑","uri":"/posts/cloud/%E8%85%BE%E4%BA%91%E4%BA%91%E5%87%BD%E6%95%B0%E9%83%A8%E7%BD%B2%E5%8F%8A%E5%9D%91/"},{"categories":null,"content":"1.Redis 是一个基于内存的高性能key-value数据库。 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:1:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"2.Redis相比memcached有哪些优势： memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型 redis的速度比memcached快很多 redis可以持久化其数据 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:2:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"3.Redis是单线程 redis利用队列技术将并发访问变为串行访问，消除了传统数据库串行控制的开销 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:3:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"4.Reids常用5种数据类型 string，list，set，sorted set，hash ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:4:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"6.Reids6种淘汰策略： noeviction: 不删除策略, 达到最大内存限制时, 如果需要更多内存, 直接返回错误信息。大多数写命令都会导致占用更多的内存(有极少数会例外。 **allkeys-lru:**所有key通用; 优先删除最近最少使用(less recently used ,LRU) 的 key。 **volatile-lru:**只限于设置了 expire 的部分; 优先删除最近最少使用(less recently used ,LRU) 的 key。 **allkeys-random:**所有key通用; 随机删除一部分 key。 volatile-random: 只限于设置了 expire 的部分; 随机删除一部分 key。 volatile-ttl: 只限于设置了 expire 的部分; 优先删除剩余时间(time to live,TTL) 短的key。 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:5:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"7.Redis的并发竞争问题如何解决? 单进程单线程模式，采用队列模式将并发访问变为串行访问。Redis本身没有锁的概念，Redis对于多个客户端连接并不存在竞争，利用setnx实现锁。 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:6:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"8.Redis是使用c语言开发的。 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:7:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"9.Redis前端启动命令 ./redis-server ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:8:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"10.Reids支持的语言： java、C、C#、C++、php、Node.js、Go等。 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:9:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"11.Redis 持久化方案： Rdb 和 Aof ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:10:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"12.Redis 的主从复制 持久化保证了即使redis服务重启也不会丢失数据，因为redis服务重启后会将硬盘上持久化的数据恢复到内存中，但是当redis服务器的硬盘损坏了可能会导致数据丢失，如果通过redis的主从复制机制就可以避免这种单点故障， ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:11:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"13.Redis是单线程的，但Redis为什么这么快？ 1、完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)； 2、数据结构简单，对数据操作也简单，Redis中的数据结构是专门进行设计的； 3、采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗； 4、使用多路I/O复用模型，非阻塞IO；这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程 5、使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求； ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:12:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"14.为什么Redis是单线程的？ Redis是基于内存的操作，CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存的大小或者网络带宽。既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了（毕竟采用多线程会有很多麻烦！）。 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:13:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"15.Redis info查看命令：info memory ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:14:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"16.Redis内存模型 used_memory：Redis分配器分配的内存总量（单位是字节），包括使用的虚拟内存（即swap）；Redis分配器后面会介绍。used_memory_human只是显示更友好。 used_memory_rss**：**Redis进程占据操作系统的内存（单位是字节），与top及ps命令看到的值是一致的；除了分配器分配的内存之外，used_memory_rss还包括进程运行本身需要的内存、内存碎片等，但是不包括虚拟内存。 mem_fragmentation_ratio**：**内存碎片比率，该值是used_memory_rss / used_memory的比值。 mem_allocator**：**Redis使用的内存分配器，在编译时指定；可以是 libc 、jemalloc或者tcmalloc，默认是jemalloc；截图中使用的便是默认的jemalloc。 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:15:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"17.Redis内存划分 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:16:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"数据 作为数据库，数据是最主要的部分；这部分占用的内存会统计在used_memory中。 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:17:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"进程本身运行需要的内存 Redis主进程本身运行肯定需要占用内存，如代码、常量池等等；这部分内存大约几兆，在大多数生产环境中与Redis数据占用的内存相比可以忽略。这部分内存不是由jemalloc分配，因此不会统计在used_memory中。 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:18:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"缓冲内存 缓冲内存包括客户端缓冲区、复制积压缓冲区、AOF缓冲区等；其中，客户端缓冲存储客户端连接的输入输出缓冲；复制积压缓冲用于部分复制功能；AOF缓冲区用于在进行AOF重写时，保存最近的写入命令。在了解相应功能之前，不需要知道这些缓冲的细节；这部分内存由jemalloc分配，因此会统计在used_memory中。 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:19:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"内存碎片 内存碎片是Redis在分配、回收物理内存过程中产生的。例如，如果对数据的更改频繁，而且数据之间的大小相差很大，可能导致redis释放的空间在物理内存中并没有释放，但redis又无法有效利用，这就形成了内存碎片。内存碎片不会统计在used_memory中。 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:20:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"18.Redis对象有5种类型 无论是哪种类型，Redis都不会直接存储，而是通过redisObject对象进行存储。 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:21:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"19.Redis没有直接使用C字符串 (即以空字符’\\0’结尾的字符数组)作为默认的字符串表示，而是使用了SDS。SDS是简单动态字符串(Simple Dynamic String)的缩写。 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:22:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"20.Reidis的SDS在C字符串的基础上加入了free和len字段 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:23:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"21.Reids主从复制 复制是高可用Redis的基础，哨兵和集群都是在复制基础上实现高可用的。复制主要实现了数据的多机备份，以及对于读操作的负载均衡和简单的故障恢复。缺陷：故障恢复无法自动化；写操作无法负载均衡；存储能力受到单机的限制。 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:24:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"22.Redis哨兵 在复制的基础上，哨兵实现了自动化的故障恢复。缺陷：写操作无法负载均衡；存储能力受到单机的限制。 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:25:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"23.Reids持久化触发条件 RDB持久化的触发分为手动触发和自动触发两种。 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:26:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"24.Redis 开启AOF Redis服务器默认开启RDB，关闭AOF；要开启AOF，需要在配置文件中配置： appendonly yes ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:27:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"25.AOF常用配置总结 下面是AOF常用的配置项，以及默认值；前面介绍过的这里不再详细介绍。 appendonly no：是否开启AOF appendfilename “appendonly.aof”：AOF文件名 dir ./：RDB文件和AOF文件所在目录 appendfsync everysec：fsync持久化策略 no-appendfsync-on-rewrite no：AOF重写期间是否禁止fsync；如果开启该选项，可以减轻文件重写时CPU和硬盘的负载（尤其是硬盘），但是可能会丢失AOF重写期间的数据；需要在负载和安全性之间进行平衡 auto-aof-rewrite-percentage 100：文件重写触发条件之一 auto-aof-rewrite-min-size 64mb：文件重写触发提交之一 aof-load-truncated yes：如果AOF文件结尾损坏，Redis启动时是否仍载入AOF文件 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:28:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"26.RDB和AOF的优缺点 RDB持久化 优点：RDB文件紧凑，体积小，网络传输快，适合全量复制；恢复速度比AOF快很多。当然，与AOF相比，RDB最重要的优点之一是对性能的影响相对较小。 缺点：RDB文件的致命缺点在于其数据快照的持久化方式决定了必然做不到实时持久化，而在数据越来越重要的今天，数据的大量丢失很多时候是无法接受的，因此AOF持久化成为主流。此外，RDB文件需要满足特定格式，兼容性差（如老版本的Redis不兼容新版本的RDB文件）。 AOF持久化 与RDB持久化相对应，AOF的优点在于支持秒级持久化、兼容性好，缺点是文件大、恢复速度慢、对性能影响大。 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:29:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"27.持久化策略选择 （1）如果Redis中的数据完全丢弃也没有关系（如Redis完全用作DB层数据的cache），那么无论是单机，还是主从架构，都可以不进行任何持久化。 （2）在单机环境下（对于个人开发者，这种情况可能比较常见），如果可以接受十几分钟或更多的数据丢失，选择RDB对Redis的性能更加有利；如果只能接受秒级别的数据丢失，应该选择AOF。 （3）但在多数情况下，我们都会配置主从环境，slave的存在既可以实现数据的热备，也可以进行读写分离分担Redis读请求，以及在master宕掉后继续提供服务。 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:30:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"28.redis缓存被击穿处理机制 使用mutex。简单地来说，就是在缓存失效的时候（判断拿出来的值为空），不是立即去load db，而是先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX或者Memcache的ADD）去set一个mutex key，当操作返回成功时，再进行load db的操作并回设缓存；否则，就重试整个get缓存的方法 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:31:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"29.Redis还提供的高级工具 像慢查询分析、性能测试、Pipeline、事务、Lua自定义命令、Bitmaps、HyperLogLog、发布/订阅、Geo等个性化功能。 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:32:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"30.Redis常用管理命令 # dbsize 返回当前数据库 key 的数量。 # info 返回当前 redis 服务器状态和一些统计信息。 # monitor 实时监听并返回redis服务器接收到的所有请求信息。 # shutdown 把数据同步保存到磁盘上，并关闭redis服务。 # config get parameter 获取一个 redis 配置参数信息。（个别参数可能无法获取） # config set parameter value 设置一个 redis 配置参数信息。（个别参数可能无法获取） # config resetstat 重置 info 命令的统计信息。（重置包括：keyspace 命中数、 # keyspace 错误数、 处理命令数，接收连接数、过期 key 数） # debug object key 获取一个 key 的调试信息。 # debug segfault 制造一次服务器当机。 # flushdb 删除当前数据库中所有 key,此方法不会失败。小心慎用 # flushall 删除全部数据库中所有 key，此方法不会失败。小心慎用 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:33:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"31.Reids工具命令 #redis-server：Redis 服务器的 daemon 启动程序 #redis-cli：Redis 命令行操作工具。当然，你也可以用 telnet 根据其纯文本协议来操作 #redis-benchmark：Redis 性能测试工具，测试 Redis 在你的系统及你的配置下的读写性能 $redis-benchmark -n 100000 –c 50 #模拟同时由 50 个客户端发送 100000 个 SETs/GETs 查询 #redis-check-aof：更新日志检查 #redis-check-dump：本地数据库检查 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:34:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"32.为什么需要持久化？ 由于Redis是一种内存型数据库，即服务器在运行时，系统为其分配了一部分内存存储数据，一旦服务器挂了，或者突然宕机了，那么数据库里面的数据将会丢失，为了使服务器即使突然关机也能保存数据，必须通过持久化的方式将数据从内存保存到磁盘中。 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:35:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"33.判断key是否存在 exists key +key名字 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:36:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"34.删除key del key1 key2 ... ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:37:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"35.缓存和数据库间数据一致性问题 分布式环境下（单机就不用说了）非常容易出现缓存和数据库间的数据一致性问题，针对这一点的话，只能说，如果你的项目对缓存的要求是强一致性的，那么请不要使用缓存。我们只能采取合适的策略来降低缓存和数据库间数据不一致的概率，而无法保证两者间的强一致性。合适的策略包括 合适的缓存更新策略，更新数据库后要及时更新缓存、缓存失败时增加重试机制，例如MQ模式的消息队列。 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:38:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"36.布隆过滤器 bloomfilter就类似于一个hash set，用于快速判某个元素是否存在于集合中，其典型的应用场景就是快速判断一个key是否存在于某容器，不存在就直接返回。布隆过滤器的关键就在于hash算法和容器大小 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:39:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"37.缓存雪崩问题 存在同一时间内大量键过期（失效），接着来的一大波请求瞬间都落在了数据库中导致连接异常。 解决方案： 1、也是像解决缓存穿透一样加锁排队。 2、建立备份缓存，缓存A和缓存B，A设置超时时间，B不设值超时时间，先从A读缓存，A没有读B，并且更新A缓存和B缓存; ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:40:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"38.缓存并发问题 这里的并发指的是多个redis的client同时set key引起的并发问题。比较有效的解决方案就是把redis.set操作放在队列中使其串行化，必须的一个一个执行，具体的代码就不上了，当然加锁也是可以的，至于为什么不用redis中的事务，留给各位看官自己思考探究。 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:41:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"39.Redis分布式 redis支持主从的模式。原则：Master会将数据同步到slave，而slave不会将数据同步到master。Slave启动时会连接master来同步数据。 这是一个典型的分布式读写分离模型。我们可以利用master来插入数据，slave提供检索服务。这样可以有效减少单个机器的并发访问数量 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:42:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"40.读写分离模型 通过增加Slave DB的数量，读的性能可以线性增长。为了避免Master DB的单点故障，集群一般都会采用两台Master DB做双机热备，所以整个集群的读和写的可用性都非常高。读写分离架构的缺陷在于，不管是Master还是Slave，每个节点都必须保存完整的数据，如果在数据量很大的情况下，集群的扩展能力还是受限于单个节点的存储能力，而且对于Write-intensive类型的应用，读写分离架构并不适合。 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:43:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"41.数据分片模型 为了解决读写分离模型的缺陷，可以将数据分片模型应用进来。 可以将每个节点看成都是独立的master，然后通过业务实现数据分片。 结合上面两种模型，可以将每个master设计成由一个master和多个slave组成的模型。 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:44:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"42. redis常见性能问题和解决方案： Master最好不要做任何持久化工作，如RDB内存快照和AOF日志文件 如果数据比较重要，某个Slave开启AOF备份数据，策略设置为每秒同步一次 为了主从复制的速度和连接的稳定性，Master和Slave最好在同一个局域网内 尽量避免在压力很大的主库上增加从库 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:45:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"43.redis通讯协议 RESP 是redis客户端和服务端之前使用的一种通讯协议；RESP 的特点：实现简单、快速解析、可读性好 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:46:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"44.Redis分布式锁实现 先拿setnx来争抢锁，抢到之后，再用expire给锁加一个过期时间防止锁忘记了释放。**如果在setnx之后执行expire之前进程意外crash或者要重启维护了，那会怎么样？**set指令有非常复杂的参数，这个应该是可以同时把setnx和expire合成一条指令来用的！ ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:47:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"45.Redis做异步队列 一般使用list结构作为队列，rpush生产消息，lpop消费消息。当lpop没有消息的时候，要适当sleep一会再重试。缺点：在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列如rabbitmq等。**能不能生产一次消费多次呢？**使用pub/sub主题订阅者模式，可以实现1:N的消息队列。 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:48:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"46.Redis中海量数据的正确操作方式 利用SCAN系列命令（SCAN、SSCAN、HSCAN、ZSCAN）完成数据迭代。 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:49:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"47.SCAN系列命令注意事项 SCAN的参数没有key，因为其迭代对象是DB内数据； 返回值都是数组，第一个值都是下一次迭代游标； 时间复杂度：每次请求都是O(1)，完成所有迭代需要O(N)，N是元素数量； 可用版本：version \u003e= 2.8.0； ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:50:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"48.Redis 管道 Pipeline 在某些场景下我们在一次操作中可能需要执行多个命令，而如果我们只是一个命令一个命令去执行则会浪费很多网络消耗时间，如果将命令一次性传输到 Redis中去再执行，则会减少很多开销时间。但是需要注意的是 pipeline中的命令并不是原子性执行的，也就是说管道中的命令到达 Redis服务器的时候可能会被其他的命令穿插 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:51:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"49.事务不支持回滚 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:52:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"50.手写一个 LRU 算法 class LRUCache\u003cK, V\u003e extends LinkedHashMap\u003cK, V\u003e { private final int CACHE_SIZE; /** * 传递进来最多能缓存多少数据 * * @param cacheSize 缓存大小 */ public LRUCache(int cacheSize) { // true 表示让 linkedHashMap 按照访问顺序来进行排序，最近访问的放在头部，最老访问的放在尾部。 super((int) Math.ceil(cacheSize / 0.75) + 1, 0.75f, true); CACHE_SIZE = cacheSize; } @Override protected boolean removeEldestEntry(Map.Entry\u003cK, V\u003e eldest) { // 当 map中的数据量大于指定的缓存个数的时候，就自动删除最老的数据。 return size() \u003e CACHE_SIZE; } } ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:53:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"51.多节点 Redis 分布式锁：Redlock 算法 获取当前时间（start）。 依次向 N 个 Redis节点请求锁。请求锁的方式与从单节点 Redis获取锁的方式一致。为了保证在某个 Redis节点不可用时该算法能够继续运行，获取锁的操作都需要设置超时时间，需要保证该超时时间远小于锁的有效时间。这样才能保证客户端在向某个 Redis节点获取锁失败之后，可以立刻尝试下一个节点。 计算获取锁的过程总共消耗多长时间（consumeTime = end - start）。如果客户端从大多数 Redis节点（\u003e= N/2 + 1) 成功获取锁，并且获取锁总时长没有超过锁的有效时间，这种情况下，客户端会认为获取锁成功，否则，获取锁失败。 如果最终获取锁成功，锁的有效时间应该重新设置为锁最初的有效时间减去 consumeTime。 如果最终获取锁失败，客户端应该立刻向所有 Redis节点发起释放锁的请求。 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:54:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"52.Redis 中设置过期时间主要通过以下四种方式 expire key seconds：设置 key 在 n 秒后过期； pexpire key milliseconds：设置 key 在 n 毫秒后过期； expireat key timestamp：设置 key 在某个时间戳（精确到秒）之后过期； pexpireat key millisecondsTimestamp：设置 key 在某个时间戳（精确到毫秒）之后过期； ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:55:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"53.Reids三种不同删除策略 定时删除：在设置键的过期时间的同时，创建一个定时任务，当键达到过期时间时，立即执行对键的删除操作 惰性删除：放任键过期不管，但在每次从键空间获取键时，都检查取得的键是否过期，如果过期的话，就删除该键，如果没有过期，就返回该键 定期删除：每隔一点时间，程序就对数据库进行一次检查，删除里面的过期键，至于要删除多少过期键，以及要检查多少个数据库，则由算法决定。 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:56:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"54.定时删除 **优点：**对内存友好，定时删除策略可以保证过期键会尽可能快地被删除，并释放国期间所占用的内存 **缺点：**对cpu时间不友好，在过期键比较多时，删除任务会占用很大一部分cpu时间，在内存不紧张但cpu时间紧张的情况下，将cpu时间用在删除和当前任务无关的过期键上，影响服务器的响应时间和吞吐量 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:57:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"55.定期删除 由于定时删除会占用太多cpu时间，影响服务器的响应时间和吞吐量以及惰性删除浪费太多内存，有内存泄露的危险，所以出现一种整合和折中这两种策略的定期删除策略。 定期删除策略每隔一段时间执行一次删除过期键操作，并通过限制删除操作执行的时长和频率来减少删除操作对CPU时间的影响。 定时删除策略有效地减少了因为过期键带来的内存浪费。 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:58:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"56.惰性删除 **优点：**对cpu时间友好，在每次从键空间获取键时进行过期键检查并是否删除，删除目标也仅限当前处理的键，这个策略不会在其他无关的删除任务上花费任何cpu时间。 **缺点：**对内存不友好，过期键过期也可能不会被删除，导致所占的内存也不会释放。甚至可能会出现内存泄露的现象，当存在很多过期键，而这些过期键又没有被访问到，这会可能导致它们会一直保存在内存中，造成内存泄露。 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:59:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"57.Reids 管理工具：Redis Manager 2.0 github地址 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:60:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"58.Redis常见的几种缓存策略 Cache-Aside Read-Through Write-Through Write-Behind ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:61:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"59.Redis Module 实现布隆过滤器 Redis module 是Redis 4.0 以后支持的新的特性，这里很多国外牛逼的大学和机构提供了很多牛逼的Module 只要编译引入到Redis 中就能轻松的实现我们某些需求的功能。在Redis 官方Module 中有一些我们常见的一些模块，我们在这里就做一个简单的使用。 neural-redis 主要是神经网络的机器学，集成到redis 可以做一些机器训练感兴趣的可以尝试 RedisSearch 主要支持一些富文本的的搜索 RedisBloom 支持分布式环境下的Bloom 过滤器 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:62:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"60.Redis 到底是怎么实现“附近的人” ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:63:0","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"使用方式 GEOADD key longitude latitude member [longitude latitude member ...] 将给定的位置对象（纬度、经度、名字）添加到指定的key。其中，key为集合名称，member为该经纬度所对应的对象。在实际运用中，当所需存储的对象数量过多时，可通过设置多key(如一个省一个key)的方式对对象集合变相做sharding，避免单集合数量过多。 成功插入后的返回值： (integer) N 其中N为成功插入的个数。 ","date":"2022-03-23","objectID":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/:63:1","tags":null,"title":"Redis面试题","uri":"/posts/draft/redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"1. SQL的生命周期？ 应用服务器与数据库服务器建立一个连接 数据库进程拿到请求sql 解析并生成执行计划，执行 读取数据到内存并进行逻辑处理 通过步骤一的连接，发送结果到客户端 关掉连接，释放资源 2. 大表数据查询，怎么优化 优化shema、sql语句+索引； 第二加缓存，memcached, redis； 主从复制，读写分离； 垂直拆分，根据你模块的耦合度，将一个大的系统分为多个小的系统，也就是分布式系统； 水平切分，针对数据量大的表，这一步最麻烦，最能考验技术水平，要选择一个合理的sharding key, 为了有好的查询效率，表结构也要改动，做一定的冗余，应用也要改，sql中尽量带sharding key，将数据定位到限定的表上去查，而不是扫描全部的表； 3. 超大分页怎么处理？ 超大的分页一般从两个方向上来解决. 数据库层面,这也是我们主要集中关注的(虽然收效没那么大),类似于select * from table where age \u003e 20 limit 1000000,10这种查询其实也是有可以优化的余地的. 这条语句需要load1000000数据然后基本上全部丢弃,只取10条当然比较慢. 当时我们可以修改为select * from table where id in (select id from table where age \u003e 20 limit 1000000,10).这样虽然也load了一百万的数据,但是由于索引覆盖,要查询的所有字段都在索引中,所以速度会很快. 同时如果ID连续的好,我们还可以select * from table where id \u003e 1000000 limit 4,效率也是不错的,优化的可能性有许多种,但是核心思想都一样,就是减少load的数据. 从需求的角度减少这种请求…主要是不做类似的需求(直接跳转到几百万页之后的具体某一页.只允许逐页查看或者按照给定的路线走,这样可预测,可缓存)以及防止ID泄漏且连续被人恶意攻击. 解决超大分页,其实主要是靠缓存,可预测性的提前查到内容,缓存至redis等k-V数据库中,直接返回即可. 在阿里巴巴《Java开发手册》中,对超大分页的解决办法是类似于上面提到的第一种. 【推荐】利用延迟关联或者子查询优化超多分页场景。 说明：MySQL并不是跳过offset行，而是取offset+N行，然后返回放弃前offset行，返回N行，那当offset特别大的时候，效率就非常的低下，要么控制返回的总页数，要么对超过特定阈值的页数进行SQL改写。 正例：先快速定位需要获取的id段，然后再关联： SELECT a.* FROM 表1 a, (select id from 表1 where 条件 LIMIT 100000,20 ) b where a.id=b.id 5. mysql 分页 LIMIT 子句可以被用于强制 SELECT 语句返回指定的记录数。LIMIT 接受一个或两个数字参数。参数必须是一个整数常量。如果给定两个参数，第一个参数指定第一个返回记录行的偏移量，第二个参数指定返回记录行的最大数目。初始记录行的偏移量是 0(而不是 1) mysql\u003e SELECT * FROM table LIMIT 5,10; // 检索记录行 6-15 为了检索从某一个偏移量到记录集的结束所有的记录行，可以指定第二个参数为 -1： mysql\u003e SELECT * FROM table LIMIT 95,-1; // 检索记录行 96-last. 如果只给定一个参数，它表示返回最大的记录行数目： mysql\u003e SELECT * FROM table LIMIT 5; //检索前 5 个记录行 换句话说，LIMIT n 等价于 LIMIT 0,n。 6. 慢查询日志 用于记录执行时间超过某个临界值的SQL日志，用于快速定位慢查询，为我们的优化做参考。 开启慢查询日志 配置项：slow_query_log 可以使用show variables like ‘slov_query_log’查看是否开启，如果状态值为OFF，可以使用set GLOBAL slow_query_log = on来开启，它会在datadir下产生一个xxx-slow.log的文件。 设置临界时间 配置项：long_query_time 查看：show VARIABLES like ‘long_query_time’，单位秒 设置：set long_query_time=0.5 实操时应该从长时间设置到短的时间，即将最慢的SQL优化掉 查看日志，一旦SQL超过了我们设置的临界时间就会被记录到xxx-slow.log中 7. 关心过业务系统里面的sql耗时吗？统计过慢查询吗？对慢查询都怎么优化过？ 在业务系统中，除了使用主键进行的查询，其他的我都会在测试库上测试其耗时，慢查询的统计主要由运维在做，会定期将业务中的慢查询反馈给我们。 慢查询的优化首先要搞明白慢的原因是什么？是查询条件没有命中索引？是load了不需要的数据列？还是数据量太大？ 所以优化也是针对这三个方向来的， 首先分析语句，看看是否load了额外的数据，可能是查询了多余的行并且抛弃掉了，可能是加载了许多结果中并不需要的列，对语句进行分析以及重写。 分析语句的执行计划，然后获得其使用索引的情况，之后修改语句或者修改索引，使得语句可以尽可能的命中索引。 如果对语句的优化已经无法进行，可以考虑表中的数据量是否太大，如果是的话可以进行横向或者纵向的分表。 8. 为什么要尽量设定一个主键？ 主键是数据库确保数据行在整张表唯一性的保障，即使业务上本张表没有主键，也建议添加一个自增长的ID列作为主键。设定了主键之后，在后续的删改查的时候可能更加快速以及确保操作数据范围安全。 9. 主键使用自增ID还是UUID？ 推荐使用自增ID，不要使用UUID。 因为在InnoDB存储引擎中，主键索引是作为聚簇索引存在的，也就是说，主键索引的B+树叶子节点上存储了主键索引以及全部的数据(按照顺序)，如果主键索引是自增ID，那么只需要不断向后排列即可，如果是UUID，由于到来的ID与原来的大小不确定，会造成非常多的数据插入，数据移动，然后导致产生很多的内存碎片，进而造成插入性能的下降。 总之，在数据量大一些的情况下，用自增主键性能会好一些。 关于主键是聚簇索引，如果没有主键，InnoDB会选择一个唯一键来作为聚簇索引，如果没有唯一键，会生成一个隐式的主键。 10. 字段为什么要求定义为not null？ null值会占用更多的字节，且会在程序中造成很多与预期不符的情况。 11. 如果要存储用户的密码散列，应该使用什么字段进行存储？ 密码散列，盐，用户身份证号等固定长度的字符串应该使用char而不是varchar来存储，这样可以节省空间且提高检索效率。 12. 优化查询过程中的数据访问 访问数据太多导致查询性能下降 确定应用程序是否在检索大量超过需要的数据，可能是太多行或列 确认MySQL服务器是否在分析大量不必要的数据行 避免犯如下SQL语句错误 查询不需要的数据。解决办法：使用limit解决 多表关联返回全部列。解决办法：指定列名 总是返回全部列。解决办法：避免使用SELECT * 重复查询相同的数据。解决办法：可以缓存数据，下次直接读取缓存 是否在扫描额外的记录。解决办法： 使用explain进行分析，如果发现查询需要扫描大量的数据，但只返回少数的行，可以通过如下技巧去优化： 使用索引覆盖扫描，把所有的列都放到索引中，这样存储引擎不需要回表获取对应行就可以返回结果。 改变数据库和表的结构，修改数据表范式 重写SQL语句，让优化器可以以更优的方式执行查询。 13. 优化长难的查询语句 一个复杂查询还是多个简单查询 MySQL内部每秒能扫描内存中上百万行数据，相比之下，响应数据给客户端就要慢得多 使用尽可能小的查询是好的，但是有时将一个大的查询分解为多个小的查询是很有必要的。 切分查询 将一个大的查询分为多个小的相同的查询 一次性删除1000万的数据要比一次删除1万，暂停一会的方案更加损耗服务器开销。 分解关联查询，让缓存的效率更高。 执行单个查询可以减少锁的竞争。 在应用层做关联更容易对数据库进行拆分。 查询效率会有大幅提升。 较少冗余记录的查询。 14. 优化特定类型的查询语句 count(*)会忽略所有的列，直接统计所有列数，不要使用count(列名) MyISAM中，没有任何where条件的count(*)非常快。 当有where条件时，MyISAM的count统计不一定比其它引擎快。 可以使用explain查询近似值，用近似值替代count(*) 增加汇总表 使用缓存 15. 优化关联查询 确定ON或者USING子句中是否有索引。 确保GROUP BY和ORDER BY只有一个表中的列，这样MySQL才有可能使用索引。 16. 优化子查询 用关联查询替代 优化GROUP BY和DISTINCT 这两种查询据可以使用索引来优化，是最有效的优化方法 关联查询中，使用标识列分组的效率更高 如果不需要ORDER BY，进行GROUP BY时加ORDER BY NULL，MySQL不会再进行文件排序。 WITH ROLLUP超级聚合，可以挪到应用程序处理 17. 优化LIMIT分页 LIMIT偏移量大的时候，查询效率较低 可以记录上次查询的最大ID，下次查询时直接根据该ID来查询 18. 优化UNION查询 UNION ALL的效率高于UNION 19. 优化WHERE子句 解题方法","date":"2022-03-23","objectID":"/posts/draft/mysql%E4%BC%98%E5%8C%96%E9%9D%A2%E8%AF%95/:0:0","tags":null,"title":"Mysql优化面试","uri":"/posts/draft/mysql%E4%BC%98%E5%8C%96%E9%9D%A2%E8%AF%95/"},{"categories":null,"content":"事务的四大特性？* 事务特性ACID：原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability）。 原子性是指事务包含的所有操作要么全部成功，要么全部失败回滚。 一致性是指一个事务执行之前和执行之后都必须处于一致性状态。比如a与b账户共有1000块，两人之间转账之后无论成功还是失败，它们的账户总和还是1000。 隔离性。跟隔离级别相关，如read committed，一个事务只能读到已经提交的修改。 持久性是指一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作。 ","date":"2022-03-23","objectID":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/:1:0","tags":["数据库","八股"],"title":"Mysql面试题","uri":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"数据库的三大范式 第一范式1NF 确保数据库表字段的原子性。 比如字段 userInfo: 广东省 10086' ，依照第一范式必须拆分成 userInfo: 广东省 userTel:10086两个字段。 第二范式2NF 首先要满足第一范式，另外包含两部分内容，一是表必须有一个主键；二是非主键列必须完全依赖于主键，而不能只依赖于主键的一部分。 举个例子。假定选课关系表为student_course(student_no, student_name, age, course_name, grade, credit)，主键为(student_no, course_name)。其中学分完全依赖于课程名称，姓名年龄完全依赖学号，不符合第二范式，会导致数据冗余（学生选n门课，姓名年龄有n条记录）、插入异常（插入一门新课，因为没有学号，无法保存新课记录）等问题。 可以拆分成三个表：学生：student(stuent_no, student_name, 年龄)；课程：course(course_name, credit)；选课关系：student_course_relation(student_no, course_name, grade)。 第三范式3NF 首先要满足第二范式，另外非主键列必须直接依赖于主键，不能存在传递依赖。即不能存在：非主键列 A 依赖于非主键列 B，非主键列 B 依赖于主键的情况。 假定学生关系表为Student(student_no, student_name, age, academy_id, academy_telephone)，主键为\"学号\"，其中学院id依赖于学号，而学院地点和学院电话依赖于学院id，存在传递依赖，不符合第三范式。 可以把学生关系表分为如下两个表：学生：(student_no, student_name, age, academy_id)；学院：(academy_id, academy_telephone)。 2NF和3NF的区别？ 2NF依据是非主键列是否完全依赖于主键，还是依赖于主键的一部分。 3NF依据是非主键列是直接依赖于主键，还是直接依赖于非主键。 ","date":"2022-03-23","objectID":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/:2:0","tags":["数据库","八股"],"title":"Mysql面试题","uri":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"事务隔离级别有哪些？* 先了解下几个概念：脏读、不可重复读、幻读。 脏读是指在一个事务处理过程里读取了另一个未提交的事务中的数据。 不可重复读是指在对于数据库中的某行记录，一个事务范围内多次查询却返回了不同的数据值，这是由于在查询间隔，另一个事务修改了数据并提交了。 幻读是当某个事务在读取某个范围内的记录时，另外一个事务又在该范围内插入了新的记录，当之前的事务再次读取该范围的记录时，会产生幻行，就像产生幻觉一样，这就是发生了幻读。 不可重复读和脏读的区别是，脏读是某一事务读取了另一个事务未提交的脏数据，而不可重复读则是读取了前一事务提交的数据。 幻读和不可重复读都是读取了另一条已经提交的事务，不同的是不可重复读的重点是修改，幻读的重点在于新增或者删除。 事务隔离就是为了解决上面提到的脏读、不可重复读、幻读这几个问题。 MySQL数据库为我们提供的四种隔离级别： Serializable (串行化)：通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。 Repeatable read (可重复读)：MySQL的默认事务隔离级别，它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行，解决了不可重复读的问题。 Read committed (读已提交)：一个事务只能看见已经提交事务所做的改变。可避免脏读的发生。 Read uncommitted (读未提交)：所有事务都可以看到其他未提交事务的执行结果。 查看隔离级别： select @@transaction_isolation; 设置隔离级别： set session transaction isolation level read uncommitted; ","date":"2022-03-23","objectID":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/:3:0","tags":["数据库","八股"],"title":"Mysql面试题","uri":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"索引 ","date":"2022-03-23","objectID":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/:4:0","tags":["数据库","八股"],"title":"Mysql面试题","uri":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"什么是索引？ 索引是存储引擎用于提高数据库表的访问速度的一种数据结构。 ","date":"2022-03-23","objectID":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/:4:1","tags":["数据库","八股"],"title":"Mysql面试题","uri":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"索引的优缺点？ 优点： 加快数据查找的速度 为用来排序或者是分组的字段添加索引，可以加快分组和排序的速度 加快表与表之间的连接 缺点： 建立索引需要占用物理空间 会降低表的增删改的效率，因为每次对表记录进行增删改，需要进行动态维护索引，导致增删改时间变长 ","date":"2022-03-23","objectID":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/:4:2","tags":["数据库","八股"],"title":"Mysql面试题","uri":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"索引的作用？ 数据是存储在磁盘上的，查询数据时，如果没有索引，会加载所有的数据到内存，依次进行检索，读取磁盘次数较多。有了索引，就不需要加载所有数据，因为B+树的高度一般在2-4层，最多只需要读取2-4次磁盘，查询速度大大提升。 ","date":"2022-03-23","objectID":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/:4:3","tags":["数据库","八股"],"title":"Mysql面试题","uri":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"什么情况下需要建索引？ 经常用于查询的字段 经常用于连接的字段建立索引，可以加快连接的速度 经常需要排序的字段建立索引，因为索引已经排好序，可以加快排序查询速度 ","date":"2022-03-23","objectID":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/:4:4","tags":["数据库","八股"],"title":"Mysql面试题","uri":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"什么情况下不建索引？ where条件中用不到的字段不适合建立索引 表记录较少 需要经常增删改 参与列计算的列不适合建索引 区分度不高的字段不适合建立索引，如性别等 ","date":"2022-03-23","objectID":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/:4:5","tags":["数据库","八股"],"title":"Mysql面试题","uri":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"索引的数据结构 索引的数据结构主要有B+树和哈希表，对应的索引分别为B+树索引和哈希索引。InnoDB引擎的索引类型有B+树索引和哈希索引，默认的索引类型为B+树索引。 B+树索引 B+ 树是基于B 树和叶子节点顺序访问指针进行实现，它具有B树的平衡性，并且通过顺序访问指针来提高区间查询的性能。 在 B+ 树中，节点中的 key 从左到右递增排列，如果某个指针的左右相邻 key 分别是 keyi 和 keyi+1，则该指针指向节点的所有 key 大于等于 keyi 且小于等于 keyi+1。 进行查找操作时，首先在根节点进行二分查找，找到key所在的指针，然后递归地在指针所指向的节点进行查找。直到查找到叶子节点，然后在叶子节点上进行二分查找，找出key所对应的数据项。 MySQL 数据库使用最多的索引类型是BTREE索引，底层基于B+树数据结构来实现。 mysql\u003e show index from blog\\G; *************************** 1. row *************************** Table: blog Non_unique: 0 Key_name: PRIMARY Seq_in_index: 1 Column_name: blog_id Collation: A Cardinality: 4 Sub_part: NULL Packed: NULL Null: Index_type: BTREE Comment: Index_comment: Visible: YES Expression: NULL 哈希索引 哈希索引是基于哈希表实现的，对于每一行数据，存储引擎会对索引列进行哈希计算得到哈希码，并且哈希算法要尽量保证不同的列值计算出的哈希码值是不同的，将哈希码的值作为哈希表的key值，将指向数据行的指针作为哈希表的value值。这样查找一个数据的时间复杂度就是O(1)，一般多用于精确查找。 ","date":"2022-03-23","objectID":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/:4:6","tags":["数据库","八股"],"title":"Mysql面试题","uri":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"Hash索引和B+树索引的区别？ 哈希索引不支持排序，因为哈希表是无序的。 哈希索引不支持范围查找。 哈希索引不支持模糊查询及多列索引的最左前缀匹配。 因为哈希表中会存在哈希冲突，所以哈希索引的性能是不稳定的，而B+树索引的性能是相对稳定的，每次查询都是从根节点到叶子节点。 ","date":"2022-03-23","objectID":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/:4:7","tags":["数据库","八股"],"title":"Mysql面试题","uri":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"为什么B+树比B树更适合实现数据库索引？ 由于B+树的数据都存储在叶子结点中，叶子结点均为索引，方便扫库，只需要扫一遍叶子结点即可，但是B树因为其分支结点同样存储着数据，我们要找到具体的数据，需要进行一次中序遍历按序来扫，所以B+树更加适合在区间查询的情况，而在数据库中基于范围的查询是非常频繁的，所以通常B+树用于数据库索引。 B+树的节点只存储索引key值，具体信息的地址存在于叶子节点的地址中。这就使以页为单位的索引中可以存放更多的节点。减少更多的I/O支出。 B+树的查询效率更加稳定，任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。 ","date":"2022-03-23","objectID":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/:4:8","tags":["数据库","八股"],"title":"Mysql面试题","uri":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"索引有什么分类？ 1、主键索引：名为primary的唯一非空索引，不允许有空值。 2、唯一索引：索引列中的值必须是唯一的，但是允许为空值。唯一索引和主键索引的区别是：唯一约束的列可以为null且可以存在多个null值。唯一索引的用途：唯一标识数据库表中的每条记录，主要是用来防止数据重复插入。创建唯一索引的SQL语句如下： ALTER TABLE table_name ADD CONSTRAINT constraint_name UNIQUE KEY(column_1,column_2,…); 3、组合索引：在表中的多个字段组合上创建的索引，只有在查询条件中使用了这些字段的左边字段时，索引才会被使用，使用组合索引时需遵循最左前缀原则。 4、全文索引：只有在MyISAM引擎上才能使用，只能在CHAR、VARCHAR和TEXT类型字段上使用全文索引。 ","date":"2022-03-23","objectID":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/:4:9","tags":["数据库","八股"],"title":"Mysql面试题","uri":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"什么是最左匹配原则？* 如果 SQL 语句中用到了组合索引中的最左边的索引，那么这条 SQL 语句就可以利用这个组合索引去进行匹配。当遇到范围查询(\u003e、\u003c、between、like)就会停止匹配，后面的字段不会用到索引。 对(a,b,c)建立索引，查询条件使用 a/ab/abc 会走索引，使用 bc 不会走索引。 对(a,b,c,d)建立索引，查询条件为a = 1 and b = 2 and c \u003e 3 and d = 4，那么a、b和c三个字段能用到索引，而d无法使用索引。因为遇到了范围查询。 如下图，对(a, b) 建立索引，a 在索引树中是全局有序的，而 b 是全局无序，局部有序（当a相等时，会根据b进行排序）。直接执行b = 2这种查询条件无法使用索引。 当a的值确定的时候，b是有序的。例如a = 1时，b值为1，2是有序的状态。当a = 2时候，b的值为1，4也是有序状态。 当执行a = 1 and b = 2时a和b字段能用到索引。而执行a \u003e 1 and b = 2时，a字段能用到索引，b字段用不到索引。因为a的值此时是一个范围，不是固定的，在这个范围内b值不是有序的，因此b字段无法使用索引。 ","date":"2022-03-23","objectID":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/:4:10","tags":["数据库","八股"],"title":"Mysql面试题","uri":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"什么是聚集索引？ InnoDB使用表的主键构造主键索引树，同时叶子节点中存放的即为整张表的记录数据。聚集索引叶子节点的存储是逻辑上连续的，使用双向链表连接，叶子节点按照主键的顺序排序，因此对于主键的排序查找和范围查找速度比较快。 聚集索引的叶子节点就是整张表的行记录。InnoDB 主键使用的是聚簇索引。聚集索引要比非聚集索引查询效率高很多。 对于InnoDB来说，聚集索引一般是表中的主键索引，如果表中没有显示指定主键，则会选择表中的第一个不允许为NULL的唯一索引。如果没有主键也没有合适的唯一索引，那么InnoDB内部会生成一个隐藏的主键作为聚集索引，这个隐藏的主键长度为6个字节，它的值会随着数据的插入自增。 ","date":"2022-03-23","objectID":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/:4:11","tags":["数据库","八股"],"title":"Mysql面试题","uri":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"什么是覆盖索引？ select的数据列只用从索引中就能够取得，不需要回表进行二次查询，也就是说查询列要被所使用的索引覆盖。对于innodb表的二级索引，如果索引能覆盖到查询的列，那么就可以避免对主键索引的二次查询。 不是所有类型的索引都可以成为覆盖索引。覆盖索引要存储索引列的值，而哈希索引、全文索引不存储索引列的值，所以MySQL使用b+树索引做覆盖索引。 对于使用了覆盖索引的查询，在查询前面使用explain，输出的extra列会显示为using index。 比如user_like 用户点赞表，组合索引为(user_id, blog_id)，user_id和blog_id都不为null。 explain select blog_id from user_like where user_id = 13; explain结果的Extra列为Using index，查询的列被索引覆盖，并且where筛选条件符合最左前缀原则，通过索引查找就能直接找到符合条件的数据，不需要回表查询数据。 explain select user_id from user_like where blog_id = 1; explain结果的Extra列为Using where; Using index， 查询的列被索引覆盖，where筛选条件不符合最左前缀原则，无法通过索引查找找到符合条件的数据，但可以通过索引扫描找到符合条件的数据，也不需要回表查询数据。 ","date":"2022-03-23","objectID":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/:4:12","tags":["数据库","八股"],"title":"Mysql面试题","uri":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"索引的设计原则？ 索引列的区分度越高，索引的效果越好。比如使用性别这种区分度很低的列作为索引，效果就会很差。 尽量使用短索引，对于较长的字符串进行索引时应该指定一个较短的前缀长度，因为较小的索引涉及到的磁盘I/O较少，查询速度更快。 索引不是越多越好，每个索引都需要额外的物理空间，维护也需要花费时间。 利用最左前缀原则。 ","date":"2022-03-23","objectID":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/:4:13","tags":["数据库","八股"],"title":"Mysql面试题","uri":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"索引什么时候会失效？* 导致索引失效的情况： 对于组合索引，不是使用组合索引最左边的字段，则不会使用索引 以%开头的like查询如%abc，无法使用索引；非%开头的like查询如abc%，相当于范围查询，会使用索引 查询条件中列类型是字符串，没有使用引号，可能会因为类型不同发生隐式转换，使索引失效 判断索引列是否不等于某个值时 对索引列进行运算 查询条件使用or连接，也会导致索引失效 ","date":"2022-03-23","objectID":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/:4:14","tags":["数据库","八股"],"title":"Mysql面试题","uri":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"什么是前缀索引？ 有时需要在很长的字符列上创建索引，这会造成索引特别大且慢。使用前缀索引可以避免这个问题。 前缀索引是指对文本或者字符串的前几个字符建立索引，这样索引的长度更短，查询速度更快。 创建前缀索引的关键在于选择足够长的前缀以保证较高的索引选择性。索引选择性越高查询效率就越高，因为选择性高的索引可以让MySQL在查找时过滤掉更多的数据行。 建立前缀索引的方式： // email列创建前缀索引 ALTER TABLE table_name ADD KEY(column_name(prefix_length)); ","date":"2022-03-23","objectID":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/:4:15","tags":["数据库","八股"],"title":"Mysql面试题","uri":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"常见的存储引擎有哪些？ MySQL中常用的四种存储引擎分别是： MyISAM、InnoDB、MEMORY、ARCHIVE。MySQL 5.5版本后默认的存储引擎为InnoDB。 InnoDB存储引擎 InnoDB是MySQL默认的事务型存储引擎，使用最广泛，基于聚簇索引建立的。InnoDB内部做了很多优化，如能够自动在内存中创建自适应hash索引，以加速读操作。 优点：支持事务和崩溃修复能力；引入了行级锁和外键约束。 缺点：占用的数据空间相对较大。 适用场景：需要事务支持，并且有较高的并发读写频率。 MyISAM存储引擎 数据以紧密格式存储。对于只读数据，或者表比较小、可以容忍修复操作，可以使用MyISAM引擎。MyISAM会将表存储在两个文件中，数据文件.MYD和索引文件.MYI。 优点：访问速度快。 缺点：MyISAM不支持事务和行级锁，不支持崩溃后的安全恢复，也不支持外键。 适用场景：对事务完整性没有要求；表的数据都会只读的。 MEMORY存储引擎 MEMORY引擎将数据全部放在内存中，访问速度较快，但是一旦系统奔溃的话，数据都会丢失。 MEMORY引擎默认使用哈希索引，将键的哈希值和指向数据行的指针保存在哈希索引中。 优点：访问速度较快。 缺点： 哈希索引数据不是按照索引值顺序存储，无法用于排序。 不支持部分索引匹配查找，因为哈希索引是使用索引列的全部内容来计算哈希值的。 只支持等值比较，不支持范围查询。 当出现哈希冲突时，存储引擎需要遍历链表中所有的行指针，逐行进行比较，直到找到符合条件的行。 ARCHIVE存储引擎 ARCHIVE存储引擎非常适合存储大量独立的、作为历史记录的数据。ARCHIVE提供了压缩功能，拥有高效的插入速度，但是这种引擎不支持索引，所以查询性能较差。 ","date":"2022-03-23","objectID":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/:5:0","tags":["数据库","八股"],"title":"Mysql面试题","uri":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"MyISAM和InnoDB的区别？* 是否支持行级锁 : MyISAM 只有表级锁，而InnoDB 支持行级锁和表级锁，默认为行级锁。 是否支持事务和崩溃后的安全恢复： MyISAM 不提供事务支持。而InnoDB提供事务支持，具有事务、回滚和崩溃修复能力。 是否支持外键： MyISAM不支持，而InnoDB支持。 是否支持MVCC ：MyISAM不支持，InnoDB支持。应对高并发事务，MVCC比单纯的加锁更高效。 MyISAM不支持聚集索引，InnoDB支持聚集索引。 ","date":"2022-03-23","objectID":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/:6:0","tags":["数据库","八股"],"title":"Mysql面试题","uri":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"MVCC 实现原理？* MVCC(Multiversion concurrency control) 就是同一份数据保留多版本的一种方式，进而实现并发控制。在查询的时候，通过read view和版本链找到对应版本的数据。 作用：提升并发性能。对于高并发场景，MVCC比行级锁开销更小。 MVCC 实现原理如下： MVCC 的实现依赖于版本链，版本链是通过表的三个隐藏字段实现。 DB_TRX_ID：当前事务id，通过事务id的大小判断事务的时间顺序。 DB_ROLL_PRT：回滚指针，指向当前行记录的上一个版本，通过这个指针将数据的多个版本连接在一起构成undo log版本链。 DB_ROLL_ID：主键，如果数据表没有主键，InnoDB会自动生成主键。 每条表记录大概是这样的： 使用事务更新行记录的时候，就会生成版本链，执行过程如下： 用排他锁锁住该行； 将该行原本的值拷贝到undo log，作为旧版本用于回滚； 修改当前行的值，生成一个新版本，更新事务id，使回滚指针指向旧版本的记录，这样就形成一条版本链。 下面举个例子方便大家理解。 1、初始数据如下，其中DB_ROW_ID和DB_ROLL_PTR为空。 2、事务A对该行数据做了修改，将age修改为12，效果如下： 3、之后事务B也对该行记录做了修改，将age修改为8，效果如下： 4、此时undo log有两行记录，并且通过回滚指针连在一起。 接下来了解下read view的概念。 read view可以理解成将数据在每个时刻的状态拍成“照片”记录下来。在获取某时刻t的数据时，到t时间点拍的“照片”上取数据。 在read view内部维护一个活跃事务链表，表示生成read view的时候还在活跃的事务。这个链表包含在创建read view之前还未提交的事务，不包含创建read view之后提交的事务。 不同隔离级别创建read view的时机不同。 read committed：每次执行select都会创建新的read_view，保证能读取到其他事务已经提交的修改。 repeatable read：在一个事务范围内，第一次select时更新这个read_view，以后不会再更新，后续所有的select都是复用之前的read_view。这样可以保证事务范围内每次读取的内容都一样，即可重复读。 read view的记录筛选方式 前提：DATA_TRX_ID 表示每个数据行的最新的事务ID；up_limit_id表示当前快照中的最先开始的事务；low_limit_id表示当前快照中的最慢开始的事务，即最后一个事务。 如果DATA_TRX_ID \u003c up_limit_id：说明在创建read view时，修改该数据行的事务已提交，该版本的记录可被当前事务读取到。 如果DATA_TRX_ID \u003e= low_limit_id：说明当前版本的记录的事务是在创建read view之后生成的，该版本的数据行不可以被当前事务访问。此时需要通过版本链找到上一个版本，然后重新判断该版本的记录对当前事务的可见性。 如果up_limit_id \u003c= DATA_TRX_ID \u003c low_limit_i： 需要在活跃事务链表中查找是否存在ID为DATA_TRX_ID的值的事务。 如果存在，因为在活跃事务链表中的事务是未提交的，所以该记录是不可见的。此时需要通过版本链找到上一个版本，然后重新判断该版本的可见性。 如果不存在，说明事务trx_id 已经提交了，这行记录是可见的。 总结：InnoDB 的MVCC是通过 read view 和版本链实现的，版本链保存有历史版本记录，通过read view 判断当前版本的数据是否可见，如果不可见，再从版本链中找到上一个版本，继续进行判断，直到找到一个可见的版本。 ","date":"2022-03-23","objectID":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/:7:0","tags":["数据库","八股"],"title":"Mysql面试题","uri":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"快照读和当前读 表记录有两种读取方式。 快照读：读取的是快照版本。普通的SELECT就是快照读。通过mvcc来进行并发控制的，不用加锁。 当前读：读取的是最新版本。UPDATE、DELETE、INSERT、SELECT … LOCK IN SHARE MODE、SELECT … FOR UPDATE是当前读。 快照读情况下，InnoDB通过mvcc机制避免了幻读现象。而mvcc机制无法避免当前读情况下出现的幻读现象。因为当前读每次读取的都是最新数据，这时如果两次查询中间有其它事务插入数据，就会产生幻读。 下面举个例子说明下： 1、首先，user表只有两条记录，具体如下： 2、事务a和事务b同时开启事务start transaction； 3、事务a插入数据然后提交； insert into user(user_name, user_password, user_mail, user_state) values(‘tyson’, ‘a’, ‘a’, 0); 4、事务b执行全表的update； update user set user_name = ‘a’; 5、事务b然后执行查询，查到了事务a中插入的数据。（下图左边是事务b，右边是事务a。事务开始之前只有两条记录，事务a插入一条数据之后，事务b查询出来是三条数据） 以上就是当前读出现的幻读现象。 那么MySQL是如何避免幻读？ 在快照读情况下，MySQL通过mvcc来避免幻读。 在当前读情况下，MySQL通过next-key来避免幻读（加行锁和间隙锁来实现的）。 next-key包括两部分：行锁和间隙锁。行锁是加在索引上的锁，间隙锁是加在索引之间的。 Serializable隔离级别也可以避免幻读，会锁住整张表，并发性极低，一般不会使用。 ","date":"2022-03-23","objectID":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/:8:0","tags":["数据库","八股"],"title":"Mysql面试题","uri":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"共享锁和排他锁 SELECT 的读取锁定主要分为两种方式：共享锁和排他锁。 select * from table where id\u003c6 lock in share mode;–共享锁 select * from table where id\u003c6 for update;–排他锁 这两种方式主要的不同在于LOCK IN SHARE MODE多个事务同时更新同一个表单时很容易造成死锁。 申请排他锁的前提是，没有线程对该结果集的任何行数据使用排它锁或者共享锁，否则申请会受到阻塞。在进行事务操作时，MySQL会对查询结果集的每行数据添加排它锁，其他线程对这些数据的更改或删除操作会被阻塞（只能读操作），直到该语句的事务被commit语句或rollback语句结束为止。 SELECT... FOR UPDATE 使用注意事项： for update 仅适用于innodb，且必须在事务范围内才能生效。 根据主键进行查询，查询条件为like或者不等于，主键字段产生表锁。 根据非索引字段进行查询，会产生表锁。 ","date":"2022-03-23","objectID":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/:9:0","tags":["数据库","八股"],"title":"Mysql面试题","uri":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"大表怎么优化？ 某个表有近千万数据，查询比较慢，如何优化？ 当MySQL单表记录数过大时，数据库的性能会明显下降，一些常见的优化措施如下： 限定数据的范围。比如：用户在查询历史信息的时候，可以控制在一个月的时间范围内； 读写分离： 经典的数据库拆分方案，主库负责写，从库负责读； 通过分库分表的方式进行优化，主要有垂直拆分和水平拆分。 ","date":"2022-03-23","objectID":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/:10:0","tags":["数据库","八股"],"title":"Mysql面试题","uri":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"bin log/redo log/undo log MySQL日志主要包括查询日志、慢查询日志、事务日志、错误日志、二进制日志等。其中比较重要的是 bin log（二进制日志）和 redo log（重做日志）和 undo log（回滚日志）。 bin log bin log是MySQL数据库级别的文件，记录对MySQL数据库执行修改的所有操作，不会记录select和show语句，主要用于恢复数据库和同步数据库。 redo log redo log是innodb引擎级别，用来记录innodb存储引擎的事务日志，不管事务是否提交都会记录下来，用于数据恢复。当数据库发生故障，innoDB存储引擎会使用redo log恢复到发生故障前的时刻，以此来保证数据的完整性。将参数innodb_flush_log_at_tx_commit设置为1，那么在执行commit时会将redo log同步写到磁盘。 undo log 除了记录redo log外，当进行数据修改时还会记录undo log，undo log用于数据的撤回操作，它保留了记录修改前的内容。通过undo log可以实现事务回滚，并且可以根据undo log回溯到某个特定的版本的数据，实现MVCC。 ","date":"2022-03-23","objectID":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/:11:0","tags":["数据库","八股"],"title":"Mysql面试题","uri":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"bin log和redo log有什么区别？ bin log会记录所有日志记录，包括InnoDB、MyISAM等存储引擎的日志；redo log只记录innoDB自身的事务日志。 bin log只在事务提交前写入到磁盘，一个事务只写一次；而在事务进行过程，会有redo log不断写入磁盘。 bin log是逻辑日志，记录的是SQL语句的原始逻辑；redo log是物理日志，记录的是在某个数据页上做了什么修改。 ","date":"2022-03-23","objectID":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/:12:0","tags":["数据库","八股"],"title":"Mysql面试题","uri":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"讲一下MySQL架构？ MySQL主要分为 Server 层和存储引擎层： Server 层：主要包括连接器、查询缓存、分析器、优化器、执行器等，所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图，函数等，还有一个通用的日志模块 binglog 日志模块。 存储引擎： 主要负责数据的存储和读取。server 层通过api与存储引擎进行通信。 Server 层基本组件 连接器： 当客户端连接 MySQL 时，server层会对其进行身份认证和权限校验。 查询缓存: 执行查询语句的时候，会先查询缓存，先校验这个 sql 是否执行过，如果有缓存这个 sql，就会直接返回给客户端，如果没有命中，就会执行后续的操作。 分析器: 没有命中缓存的话，SQL 语句就会经过分析器，主要分为两步，词法分析和语法分析，先看 SQL 语句要做什么，再检查 SQL 语句语法是否正确。 优化器： 优化器对查询进行优化，包括重写查询、决定表的读写顺序以及选择合适的索引等，生成执行计划。 执行器： 首先执行前会校验该用户有没有权限，如果没有权限，就会返回错误信息，如果有权限，就会根据执行计划去调用引擎的接口，返回结果。 ","date":"2022-03-23","objectID":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/:13:0","tags":["数据库","八股"],"title":"Mysql面试题","uri":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"分库分表 当单表的数据量达到1000W或100G以后，优化索引、添加从库等可能对数据库性能提升效果不明显，此时就要考虑对其进行切分了。切分的目的就在于减少数据库的负担，缩短查询的时间。 数据切分可以分为两种方式：垂直划分和水平划分。 垂直划分 垂直划分数据库是根据业务进行划分，例如购物场景，可以将库中涉及商品、订单、用户的表分别划分出成一个库，通过降低单库的大小来提高性能。同样的，分表的情况就是将一个大表根据业务功能拆分成一个个子表，例如商品基本信息和商品描述，商品基本信息一般会展示在商品列表，商品描述在商品详情页，可以将商品基本信息和商品描述拆分成两张表。 优点：行记录变小，数据页可以存放更多记录，在查询时减少I/O次数。 缺点： 主键出现冗余，需要管理冗余列； 会引起表连接JOIN操作，可以通过在业务服务器上进行join来减少数据库压力； 依然存在单表数据量过大的问题。 水平划分 水平划分是根据一定规则，例如时间或id序列值等进行数据的拆分。比如根据年份来拆分不同的数据库。每个数据库结构一致，但是数据得以拆分，从而提升性能。 优点：单库（表）的数据量得以减少，提高性能；切分出的表结构相同，程序改动较少。 缺点： 分片事务一致性难以解决 跨节点join性能差，逻辑复杂 数据分片在扩容时需要迁移 ","date":"2022-03-23","objectID":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/:14:0","tags":["数据库","八股"],"title":"Mysql面试题","uri":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"什么是分区表？ 分区表是一个独立的逻辑表，但是底层由多个物理子表组成。 当查询条件的数据分布在某一个分区的时候，查询引擎只会去某一个分区查询，而不是遍历整个表。在管理层面，如果需要删除某一个分区的数据，只需要删除对应的分区即可。 ","date":"2022-03-23","objectID":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/:15:0","tags":["数据库","八股"],"title":"Mysql面试题","uri":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"分区表类型 按照范围分区。 CREATETABLEtest_range_partition(idINTauto_increment,createdateDATETIME,primarykey(id,createdate))PARTITIONBYRANGE(TO_DAYS(createdate))(PARTITIONp201801VALUESLESSTHAN(TO_DAYS('20180201')),PARTITIONp201802VALUESLESSTHAN(TO_DAYS('20180301')),PARTITIONp201803VALUESLESSTHAN(TO_DAYS('20180401')),PARTITIONp201804VALUESLESSTHAN(TO_DAYS('20180501')),PARTITIONp201805VALUESLESSTHAN(TO_DAYS('20180601')),PARTITIONp201806VALUESLESSTHAN(TO_DAYS('20180701')),PARTITIONp201807VALUESLESSTHAN(TO_DAYS('20180801')),PARTITIONp201808VALUESLESSTHAN(TO_DAYS('20180901')),PARTITIONp201809VALUESLESSTHAN(TO_DAYS('20181001')),PARTITIONp201810VALUESLESSTHAN(TO_DAYS('20181101')),PARTITIONp201811VALUESLESSTHAN(TO_DAYS('20181201')),PARTITIONp201812VALUESLESSTHAN(TO_DAYS('20190101')));在/var/lib/mysql/data/可以找到对应的数据文件，每个分区表都有一个使用#分隔命名的表文件： -rw-r----- 1 MySQL MySQL 65 Mar 14 21:47 db.opt -rw-r----- 1 MySQL MySQL 8598 Mar 14 21:50 test\\_range\\_partition.frm -rw-r----- 1 MySQL MySQL 98304 Mar 14 21:50 test\\_range\\_partition#P#p201801.ibd -rw-r----- 1 MySQL MySQL 98304 Mar 14 21:50 test\\_range\\_partition#P#p201802.ibd -rw-r----- 1 MySQL MySQL 98304 Mar 14 21:50 test\\_range\\_partition#P#p201803.ibd list分区 对于List分区，分区字段必须是已知的，如果插入的字段不在分区时枚举值中，将无法插入。 createtabletest_list_partiotion(idintauto_increment,data_typetinyint,primarykey(id,data_type))partitionbylist(data_type)(partitionp0valuesin(0,1,2,3,4,5,6),partitionp1valuesin(7,8,9,10,11,12),partitionp2valuesin(13,14,15,16,17));hash分区 可以将数据均匀地分布到预先定义的分区中。 createtabletest_hash_partiotion(idintauto_increment,create_datedatetime,primarykey(id,create_date))partitionbyhash(year(create_date))partitions10;","date":"2022-03-23","objectID":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/:16:0","tags":["数据库","八股"],"title":"Mysql面试题","uri":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"分区的问题？ 打开和锁住所有底层表的成本可能很高。当查询访问分区表时，MySQL 需要打开并锁住所有的底层表，这个操作在分区过滤之前发生，所以无法通过分区过滤来降低此开销，会影响到查询速度。可以通过批量操作来降低此类开销，比如批量插入、LOAD DATA INFILE和一次删除多行数据。 维护分区的成本可能很高。例如重组分区，会先创建一个临时分区，然后将数据复制到其中，最后再删除原分区。 所有分区必须使用相同的存储引擎。 ","date":"2022-03-23","objectID":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/:17:0","tags":["数据库","八股"],"title":"Mysql面试题","uri":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"查询语句执行流程？ 查询语句的执行流程如下：权限校验、查询缓存、分析器、优化器、权限校验、执行器、引擎。 举个例子，查询语句如下： select * from user where id \u003e 1 and name = ‘大彬’; 首先检查权限，没有权限则返回错误； MySQL8.0以前会查询缓存，缓存命中则直接返回，没有则执行下一步； 词法分析和语法分析。提取表名、查询条件，检查语法是否有错误； 两种执行方案，先查 id \u003e 1 还是 name = '大彬'，优化器根据自己的优化算法选择执行效率最好的方案； 校验权限，有权限就调用数据库引擎接口，返回引擎的执行结果。 ","date":"2022-03-23","objectID":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/:18:0","tags":["数据库","八股"],"title":"Mysql面试题","uri":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"更新语句执行过程？ 更新语句执行流程如下：分析器、权限校验、执行器、引擎、redo log（prepare状态）、binlog、redo log（commit状态） 举个例子，更新语句如下： update user set name = ‘大彬’ where id = 1; 先查询到 id 为1的记录，有缓存会使用缓存。 拿到查询结果，将 name 更新为大彬，然后调用引擎接口，写入更新数据，innodb 引擎将数据保存在内存中，同时记录redo log，此时redo log进入 prepare状态。 执行器收到通知后记录binlog，然后调用引擎接口，提交redo log为commit状态。 更新完成。 为什么记录完redo log，不直接提交，而是先进入prepare状态？ 假设先写redo log直接提交，然后写binlog，写完redo log后，机器挂了，binlog日志没有被写入，那么机器重启后，这台机器会通过redo log恢复数据，但是这个时候binlog并没有记录该数据，后续进行机器备份的时候，就会丢失这一条数据，同时主从同步也会丢失这一条数据。 ","date":"2022-03-23","objectID":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/:19:0","tags":["数据库","八股"],"title":"Mysql面试题","uri":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"exist和in的区别？ exists用于对外表记录做筛选。exists会遍历外表，将外查询表的每一行，代入内查询进行判断。当exists里的条件语句能够返回记录行时，条件就为真，返回外表当前记录。反之如果exists里的条件语句不能返回记录行，条件为假，则外表当前记录被丢弃。 select a.\\* from A awhere exists (select 1 from B b where a.id=b.id) in是先把后边的语句查出来放到临时表中，然后遍历临时表，将临时表的每一行，代入外查询去查找。 select * from Awhere id in (select id from B) 子查询的表比较大的时候，使用exists可以有效减少总的循环次数来提升速度；当外查询的表比较大的时候，使用in可以有效减少对外查询表循环遍历来提升速度。 ","date":"2022-03-23","objectID":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/:20:0","tags":["数据库","八股"],"title":"Mysql面试题","uri":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"MySQL中int(10)和char(10)的区别？　 int(10)中的10表示的是显示数据的长度，而char(10)表示的是存储数据的长度。 ","date":"2022-03-23","objectID":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/:21:0","tags":["数据库","八股"],"title":"Mysql面试题","uri":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"truncate、delete与drop区别？ 相同点： truncate和不带where子句的delete、以及drop都会删除表内的数据。 drop、truncate都是DDL语句（数据定义语言），执行后会自动提交。 不同点： truncate 和 delete 只删除数据不删除表的结构；drop 语句将删除表的结构被依赖的约束、触发器、索引； 一般来说，执行速度: drop \u003e truncate \u003e delete。 ","date":"2022-03-23","objectID":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/:22:0","tags":["数据库","八股"],"title":"Mysql面试题","uri":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"having和where区别？ 二者作用的对象不同，where子句作用于表和视图，having作用于组。 where在数据分组前进行过滤，having在数据分组后进行过滤。 ","date":"2022-03-23","objectID":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/:23:0","tags":["数据库","八股"],"title":"Mysql面试题","uri":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"什么是MySQL主从同步？ 主从同步使得数据可以从一个数据库服务器复制到其他服务器上，在复制数据时，一个服务器充当主服务器（master），其余的服务器充当从服务器（slave）。 因为复制是异步进行的，所以从服务器不需要一直连接着主服务器，从服务器甚至可以通过拨号断断续续地连接主服务器。通过配置文件，可以指定复制所有的数据库，某个数据库，甚至是某个数据库上的某个表。 ","date":"2022-03-23","objectID":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/:24:0","tags":["数据库","八股"],"title":"Mysql面试题","uri":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"为什么要做主从同步？ 读写分离，使数据库能支撑更大的并发。 在主服务器上生成实时数据，而在从服务器上分析这些数据，从而提高主服务器的性能。 数据备份，保证数据的安全。 ","date":"2022-03-23","objectID":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/:25:0","tags":["数据库","八股"],"title":"Mysql面试题","uri":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"乐观锁和悲观锁是什么？ 数据库中的并发控制是确保在多个事务同时存取数据库中同一数据时不破坏事务的隔离性和统一性以及数据库的统一性。乐观锁和悲观锁是并发控制主要采用的技术手段。 悲观锁：假定会发生并发冲突，在查询完数据的时候就把事务锁起来，直到提交事务。实现方式：使用数据库中的锁机制。 乐观锁：假设不会发生并发冲突，只在提交操作时检查是否数据是否被修改过。给表增加version字段，在修改提交之前检查version与原来取到的version值是否相等，若相等，表示数据没有被修改，可以更新，否则，数据为脏数据，不能更新。实现方式：乐观锁一般使用版本号机制或CAS算法实现。 ","date":"2022-03-23","objectID":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/:26:0","tags":["数据库","八股"],"title":"Mysql面试题","uri":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"用过processlist吗？ show processlist 或 show full processlist 可以查看当前 MySQL 是否有压力，正在运行的SQL，有没有慢SQL正在执行。返回参数如下： id：线程ID，可以用kill id杀死某个线程 db：数据库名称 user：数据库用户 host：数据库实例的IP command：当前执行的命令，比如Sleep，Query，Connect等 time：消耗时间，单位秒 state：执行状态，主要有以下状态： Sleep，线程正在等待客户端发送新的请求 Locked，线程正在等待锁 Sending data，正在处理SELECT查询的记录，同时把结果发送给客户端 Kill，正在执行kill语句，杀死指定线程 Connect，一个从节点连上了主节点 Quit，线程正在退出 Sorting for group，正在为GROUP BY做排序 Sorting for order，正在为ORDER BY做排序 info：正在执行的SQL语句 ref https://www.nowcoder.com/discuss/837435 ","date":"2022-03-23","objectID":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/:27:0","tags":["数据库","八股"],"title":"Mysql面试题","uri":"/posts/draft/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"categories":null,"content":"系统调用 在我们运行的用户程序中，凡是与系统级别的资源有关的操作（例如文件管理、进程控制、内存管理等）都必须通过系统调用方式向OS提出服务请求，并由OS代为完成 平常我门的进程几乎都是用户态，读取用户数据，当涉及到系统操作，计算机资源的时候就要用到系统调用了 系统调用的功能与其作用一样——涉及计算机资源的操作 设备管理：完成设备的请求/释放以及设备的启动 文件管理：完成文件的读写、删除、创建等功能 进程控制：完成进程的创建、撤销、阻塞以及唤醒等功能 内存管理：完成内存的分配、回收以及获取作业占用内存区大小和地址等功能 ","date":"2022-03-18","objectID":"/posts/linux/%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8-%E7%94%A8%E6%88%B7%E6%80%81%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81/:1:0","tags":["操作系统","八股"],"title":"系统调用 用户态和内核态","uri":"/posts/linux/%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8-%E7%94%A8%E6%88%B7%E6%80%81%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81/"},{"categories":null,"content":"进程在系统上的运行分为2个级别 用户态（user mode）：用户态运行的进程可以直接读取用户程序的数据 内核态（kernel mode）：系统态运行的程序可以访问计算机的任何资源，不受限制 平常我们运行的程序都是用户态的，如果想要将进程运行在系统态则需要利用系统调用 ","date":"2022-03-18","objectID":"/posts/linux/%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8-%E7%94%A8%E6%88%B7%E6%80%81%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81/:1:1","tags":["操作系统","八股"],"title":"系统调用 用户态和内核态","uri":"/posts/linux/%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8-%E7%94%A8%E6%88%B7%E6%80%81%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81/"},{"categories":null,"content":"死锁的概念 死锁（Deadlock）：是指两个或两个以上的进程在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。称此时系统处于死锁状态或系统产生了死锁。 称这些永远在互相等待的进程为死锁进程。 所占用的资源或者需要它们进行某种合作的其它进程就会相继陷入死锁，最终可能导致整个系统处于瘫痪状态。 ","date":"2022-03-18","objectID":"/posts/linux/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%94%81/:1:0","tags":["操作系统","八股"],"title":"操作系统锁","uri":"/posts/linux/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%94%81/"},{"categories":null,"content":"死锁产生的条件 互斥条件 不可剥夺条件 占有并请求条件 循环等待条件 ","date":"2022-03-18","objectID":"/posts/linux/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%94%81/:2:0","tags":["操作系统","八股"],"title":"操作系统锁","uri":"/posts/linux/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%94%81/"},{"categories":null,"content":"死锁的破坏 ","date":"2022-03-18","objectID":"/posts/linux/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%94%81/:3:0","tags":["操作系统","八股"],"title":"操作系统锁","uri":"/posts/linux/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%94%81/"},{"categories":null,"content":"破坏互斥条件 ","date":"2022-03-18","objectID":"/posts/linux/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%94%81/:3:1","tags":["操作系统","八股"],"title":"操作系统锁","uri":"/posts/linux/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%94%81/"},{"categories":null,"content":"破坏不可剥夺条件 ","date":"2022-03-18","objectID":"/posts/linux/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%94%81/:3:2","tags":["操作系统","八股"],"title":"操作系统锁","uri":"/posts/linux/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%94%81/"},{"categories":null,"content":"破环占有并请求条件 ","date":"2022-03-18","objectID":"/posts/linux/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%94%81/:3:3","tags":["操作系统","八股"],"title":"操作系统锁","uri":"/posts/linux/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%94%81/"},{"categories":null,"content":"破坏循环等待条件 ref https://www.cnblogs.com/wkfvawl/p/11598647.html ","date":"2022-03-18","objectID":"/posts/linux/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%94%81/:3:4","tags":["操作系统","八股"],"title":"操作系统锁","uri":"/posts/linux/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%94%81/"},{"categories":null,"content":"Go 交叉编译 go 语言再啥平台都支持交叉编译，值得注意的是 cgo，在一些 linux 发行版中用的从语言库 go 并不支持，所以不能使用 cgo，再一些情况下 cgo 是可以提升运行速度的 ","date":"2022-03-15","objectID":"/posts/go/go%E4%BA%A4%E5%8F%89%E7%BC%96%E8%AF%91/:1:0","tags":["Go"],"title":"Go交叉编译","uri":"/posts/go/go%E4%BA%A4%E5%8F%89%E7%BC%96%E8%AF%91/"},{"categories":null,"content":"使用 ","date":"2022-03-15","objectID":"/posts/go/go%E4%BA%A4%E5%8F%89%E7%BC%96%E8%AF%91/:2:0","tags":["Go"],"title":"Go交叉编译","uri":"/posts/go/go%E4%BA%A4%E5%8F%89%E7%BC%96%E8%AF%91/"},{"categories":null,"content":"选择需要编译的系统 编译 linux go env -w GOOS=linux 编译 windows go env -w GOOS=windows ###选择需要编译的 cpu 架构 go env -w GOARCH=amd64 go env -w GOARCH=arm64 ","date":"2022-03-15","objectID":"/posts/go/go%E4%BA%A4%E5%8F%89%E7%BC%96%E8%AF%91/:2:1","tags":["Go"],"title":"Go交叉编译","uri":"/posts/go/go%E4%BA%A4%E5%8F%89%E7%BC%96%E8%AF%91/"},{"categories":null,"content":"支持的平台 GOOS GOARCH aix ppc64 android 386 android amd64 android arm android arm64 darwin amd64 darwin arm64 dragonfly amd64 freebsd 386 freebsd amd64 freebsd arm illumos amd64 ios arm64 js wasm linux 386 linux amd64 linux arm linux arm64 linux ppc64 linux ppc64le linux mips linux mipsle linux mips64 linux mips64le linux riscv64 linux s390x netbsd 386 netbsd amd64 netbsd arm openbsd 386 openbsd amd64 openbsd arm openbsd arm64 plan9 386 plan9 amd64 plan9 arm solaris amd64 windows 386 windows amd64 windows arm windows arm64 ","date":"2022-03-15","objectID":"/posts/go/go%E4%BA%A4%E5%8F%89%E7%BC%96%E8%AF%91/:3:0","tags":["Go"],"title":"Go交叉编译","uri":"/posts/go/go%E4%BA%A4%E5%8F%89%E7%BC%96%E8%AF%91/"},{"categories":null,"content":"前言 最近超星改网页改的厉害，导致很多网页脚本无法运行 遂使用命令行，绕过网页直接刷 ","date":"2022-03-13","objectID":"/posts/%E5%AD%A6%E4%B9%A0%E9%80%9A%E8%84%9A%E6%9C%AC%E5%AE%89%E8%A3%85%E6%89%8B%E6%9C%BA%E5%91%BD%E4%BB%A4%E8%A1%8C/:1:0","tags":["学习通"],"title":"学习通脚本安装（手机命令行）","uri":"/posts/%E5%AD%A6%E4%B9%A0%E9%80%9A%E8%84%9A%E6%9C%AC%E5%AE%89%E8%A3%85%E6%89%8B%E6%9C%BA%E5%91%BD%E4%BB%A4%E8%A1%8C/"},{"categories":null,"content":"刷前提醒 ","date":"2022-03-13","objectID":"/posts/%E5%AD%A6%E4%B9%A0%E9%80%9A%E8%84%9A%E6%9C%AC%E5%AE%89%E8%A3%85%E6%89%8B%E6%9C%BA%E5%91%BD%E4%BB%A4%E8%A1%8C/:2:0","tags":["学习通"],"title":"学习通脚本安装（手机命令行）","uri":"/posts/%E5%AD%A6%E4%B9%A0%E9%80%9A%E8%84%9A%E6%9C%AC%E5%AE%89%E8%A3%85%E6%89%8B%E6%9C%BA%E5%91%BD%E4%BB%A4%E8%A1%8C/"},{"categories":null,"content":"刷前提醒 开倍数，使用脚本有风险，出现的结果本人一概不负责 脚本仅供学习使用 这个暂时刷题功能不完善，只能刷视频，建议刷完视频后在用网页脚本刷题 只支持安卓手机 ","date":"2022-03-13","objectID":"/posts/%E5%AD%A6%E4%B9%A0%E9%80%9A%E8%84%9A%E6%9C%AC%E5%AE%89%E8%A3%85%E6%89%8B%E6%9C%BA%E5%91%BD%E4%BB%A4%E8%A1%8C/:3:0","tags":["学习通"],"title":"学习通脚本安装（手机命令行）","uri":"/posts/%E5%AD%A6%E4%B9%A0%E9%80%9A%E8%84%9A%E6%9C%AC%E5%AE%89%E8%A3%85%E6%89%8B%E6%9C%BA%E5%91%BD%E4%BB%A4%E8%A1%8C/"},{"categories":null,"content":"快速使用 点击这里下载命令行软件，安装，安装完成后打开 复制下面这一行代码，到命令行那里，粘贴，回车 curl -L -o cx.sh https://gh.fakev.cn/lyj0309/chaoxing-xuexitong-autoflush/raw/master/android.sh \u0026\u0026 chmod +x cx.sh \u0026\u0026 ./cx.sh 等待命令加载完毕，即可使用 如需再次使用，执行上面那一行代码即可 ","date":"2022-03-13","objectID":"/posts/%E5%AD%A6%E4%B9%A0%E9%80%9A%E8%84%9A%E6%9C%AC%E5%AE%89%E8%A3%85%E6%89%8B%E6%9C%BA%E5%91%BD%E4%BB%A4%E8%A1%8C/:4:0","tags":["学习通"],"title":"学习通脚本安装（手机命令行）","uri":"/posts/%E5%AD%A6%E4%B9%A0%E9%80%9A%E8%84%9A%E6%9C%AC%E5%AE%89%E8%A3%85%E6%89%8B%E6%9C%BA%E5%91%BD%E4%BB%A4%E8%A1%8C/"},{"categories":null,"content":"前言 最近超星改网页改的厉害，导致很多网页脚本无法运行 遂使用命令行，绕过网页直接刷 ","date":"2022-03-11","objectID":"/posts/%E5%AD%A6%E4%B9%A0%E9%80%9A%E8%84%9A%E6%9C%AC%E5%AE%89%E8%A3%85%E5%91%BD%E4%BB%A4%E8%A1%8C/:1:0","tags":["学习通"],"title":"学习通脚本安装（命令行）","uri":"/posts/%E5%AD%A6%E4%B9%A0%E9%80%9A%E8%84%9A%E6%9C%AC%E5%AE%89%E8%A3%85%E5%91%BD%E4%BB%A4%E8%A1%8C/"},{"categories":null,"content":"刷前提醒 开倍数，使用脚本有风险，出现的结果本人一概不负责 脚本仅供学习使用 这个暂时刷题功能不完善，只能刷视频，建议刷完视频后在用网页脚本刷题 只支持win64位 ","date":"2022-03-11","objectID":"/posts/%E5%AD%A6%E4%B9%A0%E9%80%9A%E8%84%9A%E6%9C%AC%E5%AE%89%E8%A3%85%E5%91%BD%E4%BB%A4%E8%A1%8C/:2:0","tags":["学习通"],"title":"学习通脚本安装（命令行）","uri":"/posts/%E5%AD%A6%E4%B9%A0%E9%80%9A%E8%84%9A%E6%9C%AC%E5%AE%89%E8%A3%85%E5%91%BD%E4%BB%A4%E8%A1%8C/"},{"categories":null,"content":"快速使用 点这里下载exe文件，打开，输入账号密码即可开始 脚本截图 ","date":"2022-03-11","objectID":"/posts/%E5%AD%A6%E4%B9%A0%E9%80%9A%E8%84%9A%E6%9C%AC%E5%AE%89%E8%A3%85%E5%91%BD%E4%BB%A4%E8%A1%8C/:3:0","tags":["学习通"],"title":"学习通脚本安装（命令行）","uri":"/posts/%E5%AD%A6%E4%B9%A0%E9%80%9A%E8%84%9A%E6%9C%AC%E5%AE%89%E8%A3%85%E5%91%BD%E4%BB%A4%E8%A1%8C/"},{"categories":null,"content":"参考文献 https://github.com/lyj0309/chaoxing-xuexitong-autoflush ","date":"2022-03-11","objectID":"/posts/%E5%AD%A6%E4%B9%A0%E9%80%9A%E8%84%9A%E6%9C%AC%E5%AE%89%E8%A3%85%E5%91%BD%E4%BB%A4%E8%A1%8C/:4:0","tags":["学习通"],"title":"学习通脚本安装（命令行）","uri":"/posts/%E5%AD%A6%E4%B9%A0%E9%80%9A%E8%84%9A%E6%9C%AC%E5%AE%89%E8%A3%85%E5%91%BD%E4%BB%A4%E8%A1%8C/"},{"categories":null,"content":"go提供了一个读取库encoding package main import ( \"encoding/csv\" \"log\" \"os\" ) //go语言读写csv文件 func main() { //创建一个io对象 filename:=\"Person1.csv\" f := ReadCsv(filename) //WriterCSV(filename) } //csv文件读取 func ReadCsv(filepath string) *[][]string { //打开文件(只读模式)，创建io.read接口实例 opencast,err:=os.Open(filepath) if err!=nil{ log.Println(\"csv文件打开失败！\") } defer opencast.Close() //创建csv读取接口实例 reader:=csv.NewReader(opencast) //获取一行内容，一般为第一行内容 //read,_:=reader.Read() //返回切片类型：[chen hai wei] //log.Println(read) //读取所有内容 ReadAll,err:=reader.ReadAll()//返回切片类型：[[s s ds] [a a a]] log.Println(ReadAll) return \u0026ReadAll /* 说明： 1、读取csv文件返回的内容为切片类型，可以通过遍历的方式使用或Slicer[0]方式获取具体的值。 2、同一个函数或线程内，两次调用Read()方法时，第二次调用时得到的值为每二行数据，依此类推。 3、大文件时使用逐行读取，小文件直接读取所有然后遍历，两者应用场景不一样，需要注意。 */ } //csv文件写入 func WriterCSV(path string) { //OpenFile读取文件，不存在时则创建，使用追加模式 File,err:=os.OpenFile(path,os.O_RDWR|os.O_APPEND|os.O_CREATE,0666) if err!=nil{ log.Println(\"文件打开失败！\") } defer File.Close() //创建写入接口 WriterCsv:=csv.NewWriter(File) str:=[]string{\"chen1\",\"hai1\",\"wei1\"} //需要写入csv的数据，切片类型 //写入一条数据，传入数据为切片(追加模式) err1:=WriterCsv.Write(str) if err1!=nil{ log.Println(\"WriterCsv写入文件失败\") } WriterCsv.Flush() //刷新，不刷新是无法写入的 log.Println(\"数据写入成功...\") } ","date":"2022-03-02","objectID":"/posts/go/go-csv/:0:0","tags":["Go"],"title":"Go Csv","uri":"/posts/go/go-csv/"},{"categories":null,"content":"文本操作 ","date":"2022-02-18","objectID":"/posts/draft/linux%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4/:0:0","tags":null,"title":"Linux基本命令","uri":"/posts/draft/linux%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4/"},{"categories":null,"content":"cat 查看文件 cat filename 写入文件 cat \u003e\u003e filename \u003c\u003c EOF #EOF是标记符，写什么无所谓，但EOF为大家默认 \u003e hahaha \u003e hehehe EOF #再次输入标记符表示结束，如果最初的标记符不是EOF，那么这里就需要和第一行一致 追加内容 cat \u003c\u003c EOF \u003e file1 111 222 333 EOF 杂项 ","date":"2022-02-18","objectID":"/posts/draft/linux%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4/:1:0","tags":null,"title":"Linux基本命令","uri":"/posts/draft/linux%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4/"},{"categories":null,"content":"环境变量 主要有两种环境变量，一种是含PATH的环境变量，一种则直接是键值对 含PATH的环境变量一般用于软件的导入，比如导入一个文件夹下面所有文件然后可以直接通过命令行访问，比如把mingw/src文件夹导入从而可以使用gcc 键值对环境变量则可以用来进行配置的读取，如NODEJS_ORG_MIRROR=https://npm.taobao.org/mirrors/node这个环境变量，则是告诉node使用淘宝镜像，就如同全局变量 ","date":"2022-02-18","objectID":"/posts/draft/linux%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4/:2:0","tags":null,"title":"Linux基本命令","uri":"/posts/draft/linux%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4/"},{"categories":null,"content":"读取环境变量 export命令显示当前系统定义的所有环境变量 echo $PATH命令输出当前的PATH环境变量的值 ","date":"2022-02-18","objectID":"/posts/draft/linux%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4/:2:1","tags":null,"title":"Linux基本命令","uri":"/posts/draft/linux%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4/"},{"categories":null,"content":"配置环境变量 临时变量（当前命令行有用） PATH变量 ：使用export命令直接修改PATH的值，配置MySQL进入环境变量的方法: export PATH=/home/uusama/mysql/bin:$PATH 非PATH变量： export GO_VERSION=1.17.6 永久变量 主要是修改配置文件的方式 一共有四个文件，修改方式则是把设置临时变量的句子加到文件中 /etc/profile： 此文件为系统的每个用户设置环境信息,当用户第一次登录时,该文件被执行。是系统全局针对终端环境的设置，它是login时最先被系统加载的，是它调用了/etc/bashrc，以及/etc/profile.d目录下的*.sh文件，如果有一个软件包，系统上只安装一份，供所有开发者使用，建议在/etc/profile.d下创建一个新的xxx.sh，配置环境变量。 ~/.bashrc:是用户相关的终端（shell）的环境设置，通常打开一个新终端时，默认会load里面的设置，在这里的设置不影响其它人。如果一个服务器多个开发者使用，大家都需要有自己的sdk安装和设置，那么最好就是设置它。 /etc/bashrc: 是系统全局针对终端环境的设置，修改了它，会影响所有用户的终端环境，这里一般配置终端如何与用户进行交互的增强功能等（比如sudo提示、命令找不到提示安装什么包等），新开的终端，已经load了这个配置，最后才load用户自己的 ~/.bashrc。 ~/.bash_profile:每个用户都可使用该文件输入专用于自己使用的shell信息,当用户登录时,该文件仅仅执行一次!默认情况下,他设置一些环境变量,执行用户的.bashrc文件. ","date":"2022-02-18","objectID":"/posts/draft/linux%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4/:2:2","tags":null,"title":"Linux基本命令","uri":"/posts/draft/linux%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4/"},{"categories":null,"content":"swap 创建一个swap文件,大小2G，count代表大小。 cd /var sudo dd if=/dev/zero of=swapfile bs=1024 count=2000000 chmod 0600 swapfile sudo mkswap swapfile #挂载： sudo swapon /var/swapfile #卸载： # sudo swapoff /var/swapfile 开机自己挂载 开机自动挂载SWAP分区， 编辑 /etc/fstab，末行添加： cat \u003c\u003c EOF \u003e /etc/fstab /var/swapfile swap swap defaults 0 0 EOF ","date":"2022-02-18","objectID":"/posts/draft/linux%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4/:3:0","tags":null,"title":"Linux基本命令","uri":"/posts/draft/linux%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4/"},{"categories":null,"content":"压缩 ","date":"2022-02-18","objectID":"/posts/draft/linux%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4/:4:0","tags":null,"title":"Linux基本命令","uri":"/posts/draft/linux%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4/"},{"categories":null,"content":"zip 将 /home/html/ 这个目录下所有文件和文件夹打包为当前目录下的 html.zip： zip -q -r html.zip /home/html zip *就可以压缩当前文件夹了，与别的命令有点不同，这个命令不能识别./或.必须要* ","date":"2022-02-18","objectID":"/posts/draft/linux%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4/:4:1","tags":null,"title":"Linux基本命令","uri":"/posts/draft/linux%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4/"},{"categories":null,"content":"tar 压缩 a.c文件为test.tar.gz touch a.c tar -czvf test.tar.gz a.c # a.c 解压文件 tar -xzvf test.tar.gz #a.c ","date":"2022-02-18","objectID":"/posts/draft/linux%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4/:4:2","tags":null,"title":"Linux基本命令","uri":"/posts/draft/linux%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4/"},{"categories":null,"content":"在 kibana.yml配置文件中加一行 docker exec -ti efk-kibana-1 sh -c “cat « EOF \u003e config/kibana.yml i18n.locale: \"zh-CN\" EOF \" docker exec -it -c efk-kibana-1 cat i18n.locale: \"zh-CN\" ","date":"2022-02-18","objectID":"/posts/middleware/elastic/kibana%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/:0:0","tags":["elastic"],"title":"Kibana改中文","uri":"/posts/middleware/elastic/kibana%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/"},{"categories":null,"content":"Elasticsearch8.0基本使用 https://www.elastic.co/guide/en/elasticsearch/reference/8.0/getting-started.html 官方文档 Quick start ","date":"2022-02-18","objectID":"/posts/middleware/elastic/elastic%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/:0:0","tags":["elastic"],"title":"Elasticsearch8.0基本使用","uri":"/posts/middleware/elastic/elastic%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/"},{"categories":null,"content":"简介 首先介绍几个概念，为了方便理解，这里拿数据库做类比 索引相当于表 mappings properties 相当于传统数据库中的表定义 ","date":"2022-02-18","objectID":"/posts/middleware/elastic/elastic%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/:1:0","tags":["elastic"],"title":"Elasticsearch8.0基本使用","uri":"/posts/middleware/elastic/elastic%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/"},{"categories":null,"content":"举个例子 假设我现在要创建一张叫做topic的表，有2个字段，topic和answer,类型是text 不同的是elastic不会中文分词，所以要添加分词器，如ik分词器，所以要添加analyzer这个字段 PUT topic 请求体 { \"mappings\": { \"properties\": { \"topic\": { \"type\": \"text\", \"analyzer\": \"ik_smart\" }, \"answer\": { \"type\": \"text\", \"analyzer\": \"ik_smart\" } } } } ","date":"2022-02-18","objectID":"/posts/middleware/elastic/elastic%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/:1:1","tags":["elastic"],"title":"Elasticsearch8.0基本使用","uri":"/posts/middleware/elastic/elastic%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/"},{"categories":null,"content":"es配置用户名密码 修改配置文件./config/elasticsearch.yml docker exec es bash cat « EOF \u003e ./config/elasticsearch.yml xpack.security.enabled: true xpack.security.transport.ssl.enabled: true EOF xpack.security.enabled: true xpack.security.transport.ssl.enabled: true 执行 ./bin/elasticsearch-setup-passwords interactive 设置kibana.yml elasticsearch.username: \"elastic\" elasticsearch.password: \"xxx\" ","date":"2022-02-18","objectID":"/posts/middleware/elastic/elastic%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/:2:0","tags":["elastic"],"title":"Elasticsearch8.0基本使用","uri":"/posts/middleware/elastic/elastic%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/"},{"categories":null,"content":"创建索引 PUT {{name}} 请求体 { \"mappings\": { \"properties\": { \"topic\": { \"type\": \"text\", \"analyzer\": \"ik_smart\" }, \"answer\": { \"type\": \"text\", \"analyzer\": \"ik_smart\" } } } } ","date":"2022-02-18","objectID":"/posts/middleware/elastic/elastic%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/:3:0","tags":["elastic"],"title":"Elasticsearch8.0基本使用","uri":"/posts/middleware/elastic/elastic%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/"},{"categories":null,"content":"添加数据 ","date":"2022-02-18","objectID":"/posts/middleware/elastic/elastic%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/:4:0","tags":["elastic"],"title":"Elasticsearch8.0基本使用","uri":"/posts/middleware/elastic/elastic%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/"},{"categories":null,"content":"单个数据 POST topic/_doc { \"topic\": \"1+1=2\", \"answer\": \"正确\" } #or POST logs-my_app-default/_doc { \"@timestamp\": \"2099-05-06T16:21:15.000Z\", \"event\": { \"original\": \"192.0.2.42 - - [06/May/2099:16:21:15 +0000] \\\"GET /images/bg.jpg HTTP/1.0\\\" 200 24736\" } } ","date":"2022-02-18","objectID":"/posts/middleware/elastic/elastic%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/:4:1","tags":["elastic"],"title":"Elasticsearch8.0基本使用","uri":"/posts/middleware/elastic/elastic%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/"},{"categories":null,"content":"多个数据 PUT logs-my_app-default/_bulk { \"create\": { } } { \"@timestamp\": \"2099-05-07T16:24:32.000Z\", \"event\": { \"original\": \"192.0.2.242 - - [07/May/2020:16:24:32 -0500] \\\"GET /images/hm_nbg.jpg HTTP/1.0\\\" 304 0\" } } { \"create\": { } } { \"@timestamp\": \"2099-05-08T16:25:42.000Z\", \"event\": { \"original\": \"192.0.2.255 - - [08/May/2099:16:25:42 +0000] \\\"GET /favicon.ico HTTP/1.0\\\" 200 3638\" } } #or POST topic/_bulk {\"index\":{\"_index\":\"topic\",\"_id\":\"1\"}} {\"topic\":\"乌鲁木齐惊现彩虹\",\"answer\":\"今日午后一场大雨过后，乌鲁木齐天空上出现一道彩虹\"} ","date":"2022-02-18","objectID":"/posts/middleware/elastic/elastic%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/:4:2","tags":["elastic"],"title":"Elasticsearch8.0基本使用","uri":"/posts/middleware/elastic/elastic%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/"},{"categories":null,"content":"搜索数据 GET logs-my_app-default/_search { \"query\": { \"match_all\": { } }, \"fields\": [ \"@timestamp\" ], \"_source\": false, \"sort\": [ { \"@timestamp\": \"desc\" } ] } #or GET topic/_search { \"size\": 6, \"query\": { \"multi_match\": { \"query\": \"1+1\", \"fields\": [ \"topic^2\", \"answer\" ] } } } ","date":"2022-02-18","objectID":"/posts/middleware/elastic/elastic%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/:4:3","tags":["elastic"],"title":"Elasticsearch8.0基本使用","uri":"/posts/middleware/elastic/elastic%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/"},{"categories":null,"content":"删除数据 DELETE _data_stream/logs-my_app-default ","date":"2022-02-18","objectID":"/posts/middleware/elastic/elastic%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/:4:4","tags":["elastic"],"title":"Elasticsearch8.0基本使用","uri":"/posts/middleware/elastic/elastic%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/"},{"categories":null,"content":"es安装 esver=8.0.0 # 设置系统内存 sudo sysctl -w vm.max_map_count=262144 # docker pull elasticsearch:$esver docker run --name es --net elastic -p 9200:9200 -p 9300:9300 -it docker.elastic.co/elasticsearch/elasticsearch:8.0.0 es就启动了 访问https://ip:9200就能看到，是需要密码的，密码可以从命令行看到，如果是arm则要手动生成 ","date":"2022-02-18","objectID":"/posts/middleware/elastic/elastic%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8ik%E5%88%86%E8%AF%8D%E5%99%A8/:1:0","tags":["elastic"],"title":"Elasticsearch8.0安装及使用ik分词器","uri":"/posts/middleware/elastic/elastic%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8ik%E5%88%86%E8%AF%8D%E5%99%A8/"},{"categories":null,"content":"设置密码 docker exec -it es /usr/share/elasticsearch/bin/elasticsearch-reset-password ","date":"2022-02-18","objectID":"/posts/middleware/elastic/elastic%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8ik%E5%88%86%E8%AF%8D%E5%99%A8/:1:1","tags":["elastic"],"title":"Elasticsearch8.0安装及使用ik分词器","uri":"/posts/middleware/elastic/elastic%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8ik%E5%88%86%E8%AF%8D%E5%99%A8/"},{"categories":null,"content":"分词器安装 esver=8.0.0 #安装解压 apt install unzip -y yum install unzip -y # 下载分词器 curl -L -o ik.zip https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v$esver/elasticsearch-analysis-ik-$esver.zip # wget gh.dlpu.workers.dev/https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v$esver/elasticsearch-analysis-ik-$esver.zip mkdir ik unzip -d ik ik.zip #将ik移动到容器中 docker cp ik es:/usr/share/elasticsearch/plugins rm -rf ik.zip ik docker restart es ","date":"2022-02-18","objectID":"/posts/middleware/elastic/elastic%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8ik%E5%88%86%E8%AF%8D%E5%99%A8/:2:0","tags":["elastic"],"title":"Elasticsearch8.0安装及使用ik分词器","uri":"/posts/middleware/elastic/elastic%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8ik%E5%88%86%E8%AF%8D%E5%99%A8/"},{"categories":null,"content":"yarn // 查询源 yarn config get registry // 更换国内源 yarn config set registry https://registry.npm.taobao.org/ // 恢复官方源 yarn config set registry https://registry.yarnpkg.com // 删除注册表 yarn config delete registry ","date":"2022-02-15","objectID":"/posts/front/npm%E5%92%8Cyarn%E6%8D%A2%E6%BA%90/:1:0","tags":["国内","前端"],"title":"Npm和yarn换源","uri":"/posts/front/npm%E5%92%8Cyarn%E6%8D%A2%E6%BA%90/"},{"categories":null,"content":"npm 注意 npm 更换国内镜像源之后，将无法再使用 npm search 命令，需要恢复为官方源才可以使用，如果恢复官方源后还不可使用，运行删除注册表命令后重试即可。 // 查询源 npm config get registry // 更换国内源 npm config set registry https://registry.npm.taobao.org/ // 恢复官方源 npm config set registry https://registry.npmjs.org // 删除注册表 npm config delete registry ","date":"2022-02-15","objectID":"/posts/front/npm%E5%92%8Cyarn%E6%8D%A2%E6%BA%90/:2:0","tags":["国内","前端"],"title":"Npm和yarn换源","uri":"/posts/front/npm%E5%92%8Cyarn%E6%8D%A2%E6%BA%90/"},{"categories":null,"content":"前言 railway是一个免费的PaaS平台https://railway.app,每月有5美元免费额度，如果添加支付方式则有5美元免费额度 ","date":"2022-02-12","objectID":"/posts/cloud/%E9%83%A8%E7%BD%B2cloudreve%E8%87%B3railway.app/:1:0","tags":null,"title":"部署cloudreve至railway.app","uri":"/posts/cloud/%E9%83%A8%E7%BD%B2cloudreve%E8%87%B3railway.app/"},{"categories":null,"content":"生成自己的github仓库 演示仓库 https://github.com/lyj0309/pan ","date":"2022-02-12","objectID":"/posts/cloud/%E9%83%A8%E7%BD%B2cloudreve%E8%87%B3railway.app/:2:0","tags":null,"title":"部署cloudreve至railway.app","uri":"/posts/cloud/%E9%83%A8%E7%BD%B2cloudreve%E8%87%B3railway.app/"},{"categories":null,"content":"目录说明 cr 这个文件是cloudreve的linux可执行文件,我用的3.4版本 Dockerfile，railway会通过这个自动构建镜像 FROMalpineENV PUID=1000 ENV PGID=1000 ENV TZ=\"Asia/Shanghai\"LABEL MAINTAINER=\"lyj0309\"WORKDIR/app# ADD config.ini .ADD cr .RUN echo \"\u003e\u003e\u003e\u003e\u003e\u003e update dependencies\" \\ \u0026\u0026 apk update \\ \u0026\u0026 apk add tzdata gcompat\\ \u0026\u0026 echo \"\u003e\u003e\u003e\u003e\u003e\u003e set up timezone\" \\ \u0026\u0026 cp /usr/share/zoneinfo/${TZ} /etc/localtime \\ \u0026\u0026 echo ${TZ} \u003e /etc/timezone \\ \u0026\u0026 echo \"\u003e\u003e\u003e\u003e\u003e\u003e fix premission\" \\ \u0026\u0026 chmod +x /app/crEXPOSE5212# ENTRYPOINT [\"/app/cr\",\"-c\",\"/app/config.ini\"] ENTRYPOINT [\"/app/cr\"] 神奇的是，似乎由于滥用，railway已经屏蔽了一切有关cloudreve的东西 注意： 仓库名字不要包含cloudreve 仓库文件名不要包含cloudreve 仓库文件内容不要包含cloudreve ","date":"2022-02-12","objectID":"/posts/cloud/%E9%83%A8%E7%BD%B2cloudreve%E8%87%B3railway.app/:2:1","tags":null,"title":"部署cloudreve至railway.app","uri":"/posts/cloud/%E9%83%A8%E7%BD%B2cloudreve%E8%87%B3railway.app/"},{"categories":null,"content":"安装 在railway中导入仓库 接着会自动构建app，构建成功后，在运行日志里面查看初始密码 系统应该会提示修改端口，如果没有则自己修改 端口为5212 ","date":"2022-02-12","objectID":"/posts/cloud/%E9%83%A8%E7%BD%B2cloudreve%E8%87%B3railway.app/:3:0","tags":null,"title":"部署cloudreve至railway.app","uri":"/posts/cloud/%E9%83%A8%E7%BD%B2cloudreve%E8%87%B3railway.app/"},{"categories":null,"content":"检验 railway会自动送你个域名访问 想添加自定义域名也是可以的 ","date":"2022-02-12","objectID":"/posts/cloud/%E9%83%A8%E7%BD%B2cloudreve%E8%87%B3railway.app/:4:0","tags":null,"title":"部署cloudreve至railway.app","uri":"/posts/cloud/%E9%83%A8%E7%BD%B2cloudreve%E8%87%B3railway.app/"},{"categories":null,"content":"市面上有很多博客的生成框架，hugo, wordpress, hexo 我选择hugo有以下几点 我是gopher hugo生成网站快 配置简单 官方网站https://gohugo.io/ ","date":"2022-02-11","objectID":"/posts/hugo%E5%AE%89%E8%A3%85/:0:0","tags":["other"],"title":"Hugo安装与使用","uri":"/posts/hugo%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"安装 ","date":"2022-02-11","objectID":"/posts/hugo%E5%AE%89%E8%A3%85/:1:0","tags":["other"],"title":"Hugo安装与使用","uri":"/posts/hugo%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"win 这里推荐使用choco安装, 直接 choco install hugo即可 ps: 最好把代理打开，choco会自动走代理 ","date":"2022-02-11","objectID":"/posts/hugo%E5%AE%89%E8%A3%85/:1:1","tags":["other"],"title":"Hugo安装与使用","uri":"/posts/hugo%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"生成站点 hugo new site quickstart 这时候就会生成一个名叫quickstart的文件夹，里面包含了hugo站点的一些东西 ","date":"2022-02-11","objectID":"/posts/hugo%E5%AE%89%E8%A3%85/:1:2","tags":["other"],"title":"Hugo安装与使用","uri":"/posts/hugo%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"添加主题 github上面有许许多多的主题，直接去上面搜索即可 https://github.com/search?q=hugo+theme 找到心仪的主题，下载或clone到theme文件夹 ","date":"2022-02-11","objectID":"/posts/hugo%E5%AE%89%E8%A3%85/:1:3","tags":["other"],"title":"Hugo安装与使用","uri":"/posts/hugo%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"添加页面 hugo new /posts/{name}.md name是你文章的名字，支持中文，运行后会在文件夹下面生成md文件，直接编写即可 ps:现在生成的页面是草稿页面，当你写完后去掉draft: true这一行即可变成正式页面 ","date":"2022-02-11","objectID":"/posts/hugo%E5%AE%89%E8%A3%85/:1:4","tags":["other"],"title":"Hugo安装与使用","uri":"/posts/hugo%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"配置主题 在hugo站点的跟文件夹下面有一个config.toml的配置文件，把里面的theme改成你下载的主题 每个主题的配置文件都不一样，你需要仔细浏览主题的教程 ","date":"2022-02-11","objectID":"/posts/hugo%E5%AE%89%E8%A3%85/:1:5","tags":["other"],"title":"Hugo安装与使用","uri":"/posts/hugo%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"生成预览 hugo server -D即可生成预览，包含草稿 hugo server不包含草稿 运行后会生成一个地址，访问即可预览 ","date":"2022-02-11","objectID":"/posts/hugo%E5%AE%89%E8%A3%85/:1:6","tags":["other"],"title":"Hugo安装与使用","uri":"/posts/hugo%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"生成静态文件 hugo -D包含草稿 hugo 不包含草稿 运行后，在目录下面会生吃一个public的文件夹，里面即使成品 ","date":"2022-02-11","objectID":"/posts/hugo%E5%AE%89%E8%A3%85/:1:7","tags":["other"],"title":"Hugo安装与使用","uri":"/posts/hugo%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"前言 市面上有许许多多的静态网站部署，vercel,netify,aws,azure,github pages··· 我经过多方考虑，最终选择了azure的静态网站部署。下面是一张对照表 ps: 都有免费额度,azure我用的是外币卡注册的，应该学生账号也可以 azure vercel github pages 地区\u0026速度 可选香港，速度起飞 美国aws，速度一般般 速度不慢，但github.io经常阻断 免费流量 100G 100G 自定义域名 2个 无限制 无限制 自动ssl 有 有 有 serverless Azure Functions 有 无 最大应用大小 250mb 15,000个文件 无 vercel azure firebase 综上，除了地区和速度之外，其他的也差不多，而且，香港的一般也不会阻断，所以我选择azure ","date":"2022-02-11","objectID":"/posts/hugo%E5%85%8D%E8%B4%B9%E9%83%A8%E7%BD%B2azure/:1:0","tags":["other","白嫖"],"title":"Hugo免费部署azure","uri":"/posts/hugo%E5%85%8D%E8%B4%B9%E9%83%A8%E7%BD%B2azure/"},{"categories":null,"content":"安装hugo和生成与写博客 点这里 ","date":"2022-02-11","objectID":"/posts/hugo%E5%85%8D%E8%B4%B9%E9%83%A8%E7%BD%B2azure/:2:0","tags":["other","白嫖"],"title":"Hugo免费部署azure","uri":"/posts/hugo%E5%85%8D%E8%B4%B9%E9%83%A8%E7%BD%B2azure/"},{"categories":null,"content":"部署至azure 官方文档 我采用的是github储存 ","date":"2022-02-11","objectID":"/posts/hugo%E5%85%8D%E8%B4%B9%E9%83%A8%E7%BD%B2azure/:3:0","tags":["other","白嫖"],"title":"Hugo免费部署azure","uri":"/posts/hugo%E5%85%8D%E8%B4%B9%E9%83%A8%E7%BD%B2azure/"},{"categories":null,"content":"将站点推送至github 创建github储存库 git remote add origin https://github.com/\u003cYOUR_USER_NAME\u003e/hugo-static-app git push --set-upstream origin main ","date":"2022-02-11","objectID":"/posts/hugo%E5%85%8D%E8%B4%B9%E9%83%A8%E7%BD%B2azure/:3:1","tags":["other","白嫖"],"title":"Hugo免费部署azure","uri":"/posts/hugo%E5%85%8D%E8%B4%B9%E9%83%A8%E7%BD%B2azure/"},{"categories":null,"content":"部署 打开Azure控制台 https://portal.azure.com/#create/Microsoft.StaticApp 新建web应用 主要注意两点 地区选择east aisa(香港) 使用github登录，然后选择你的库 点击创建 这时候azure就会自动生成一个github action，在.github\\workflows\\xxx.yml,然后会自动运行，就部署上去了 ","date":"2022-02-11","objectID":"/posts/hugo%E5%85%8D%E8%B4%B9%E9%83%A8%E7%BD%B2azure/:3:2","tags":["other","白嫖"],"title":"Hugo免费部署azure","uri":"/posts/hugo%E5%85%8D%E8%B4%B9%E9%83%A8%E7%BD%B2azure/"},{"categories":null,"content":"自定义域名 在你的控制台下面有个自定义域的按钮，点击，在点击添加即可 ","date":"2022-02-11","objectID":"/posts/hugo%E5%85%8D%E8%B4%B9%E9%83%A8%E7%BD%B2azure/:4:0","tags":["other","白嫖"],"title":"Hugo免费部署azure","uri":"/posts/hugo%E5%85%8D%E8%B4%B9%E9%83%A8%E7%BD%B2azure/"},{"categories":null,"content":"注意事项 在我的网站实际部署中，因为采用了atomic-algolia这个插件，所以在根目录下有package.json文件，而azure添加的那个github action文件azure-static-web-appsxxx.yml实际上并没有指定编译环境，完全是由oryx这个编译器猜的，所以这玩意猜我是npm项目，而我是hugo,导致了error 解决办法就是在github action文件加一句，rm package.json ","date":"2022-02-11","objectID":"/posts/hugo%E5%85%8D%E8%B4%B9%E9%83%A8%E7%BD%B2azure/:5:0","tags":["other","白嫖"],"title":"Hugo免费部署azure","uri":"/posts/hugo%E5%85%8D%E8%B4%B9%E9%83%A8%E7%BD%B2azure/"},{"categories":null,"content":"//459. 重复的子字符串 func repeatedSubstringPattern(s string) bool { l := len(s) for i := 1; i \u003c= l/2; i++ { if l%i == 0 { subs := s[:i] t := true for k := 0; k \u003c l/i; k++ { if s[k*i:k*i+i] != subs { t = false break } } if t { return true } } } return false } //1447. 最简分数 func simplifiedFractions(n int) (res []string) { for i := 1; i \u003c n; i++ { for k := n; k \u003e 1; k-- { if i \u003e= k { break } //判断化简 for f := 2; f \u003c= i; f++ { if i%f == 0 \u0026\u0026 k%f == 0 { goto this } } res = append(res, strconv.Itoa(i)+\"/\"+strconv.Itoa(k)) this: } } return } //268. 丢失的数字 func missingNumber(nums []int) int { arr := make([]bool, len(nums)) for _, num := range nums { arr[num] = true } for i, b := range arr { if b == false { return i } } return 0 } //258. 各位相加 func addDigits(num int) int { for { arr := getBit(num) num = 0 for _, i := range arr { num += i } if num \u003c 10 { return num } } } //242. 有效的字母异位词 func isAnagram(s string, t string) bool { m := map[int32]int{} for _, i := range s { m[i]++ } for _, i := range t { m[i]-- } for _, i := range m { if i != 0 { return false } } return true } //228. 汇总区间 func summaryRanges(nums []int) (res []string) { if len(nums) == 0 { return } k := 0 for i := 0; i \u003c len(nums)-1; i++ { if nums[i+1]-nums[i] != 1 { //生成单个 r := strconv.Itoa(nums[i]) if k != i { r = strconv.Itoa(nums[k]) + \"-\u003e\" + r } res = append(res, r) k = i + 1 } } if k == len(nums)-1 { res = append(res, strconv.Itoa(nums[len(nums)-1])) } else { res = append(res, strconv.Itoa(nums[k])+\"-\u003e\"+strconv.Itoa(nums[len(nums)-1])) } return } type MyStack struct { arr []int } //225. 用队列实现栈 func Constructor() MyStack { return MyStack{} } func (s *MyStack) Push(x int) { s.arr = append(s.arr, x) } func (s *MyStack) Pop() int { a := s.arr[len(s.arr)] s.arr = s.arr[:len(s.arr)-1] return a } func (s *MyStack) Top() int { return s.arr[len(s.arr)] } func (s *MyStack) Empty() bool { return len(s.arr) == 0 } //219. 存在重复元素 II func containsNearbyDuplicate(nums []int, k int) bool { m := make(map[int]int) for i, num := range nums { if i-m[num] \u003c= k \u0026\u0026 m[num] != 0 { return true } m[num] = i } return false } func myPow(x float64, n int) float64 { return math.Pow(x, float64(n)) } func majorityElement(nums []int) int { m := make(map[int]int) for _, num := range nums { m[num]++ if m[num] \u003e (len(nums) / 2) { return num } } return 0 } //168. Excel表列名称 func convertToTitle(columnNumber int) string { ans := []byte{} for columnNumber \u003e 0 { a0 := (columnNumber-1)%26 + 1 ans = append(ans, 'A'+byte(a0-1)) columnNumber = (columnNumber - a0) / 26 } for i, n := 0, len(ans); i \u003c n/2; i++ { ans[i], ans[n-1-i] = ans[n-1-i], ans[i] } return string(ans) } //1996. 游戏中弱角色的数量 func numberOfWeakCharacters(properties [][]int) (ans int) { sort.Slice(properties, func(i, j int) bool { p, q := properties[i], properties[j] return p[0] \u003c q[0] || p[0] == q[0] \u0026\u0026 p[1] \u003e q[1] }) var st []int for _, p := range properties { for len(st) \u003e 0 \u0026\u0026 st[len(st)-1] \u003c p[1] { st = st[:len(st)-1] ans++ } st = append(st, p[1]) } return } //171. Excel 表列序号 func titleToNumber(columnTitle string) (res int) { l := len(columnTitle) k := 1 for i := l; i \u003e 0; i-- { res += int(columnTitle[i-1]-64) * k k *= 26 } return } //202. 快乐数 func isHappy(n int) bool { m := make(map[int]bool) for { arr := getBit(n) n = 0 for _, i := range arr { n += i * i } if m[n] == true { return false } m[n] = true if n \u003c= 3 { if n == 1 { return true } else { return false } } } } //217. 存在重复元素 func containsDuplicate(nums []int) bool { if len(nums) \u003e 0 { for k, v := range nums { for _, vv := range nums[k+1:] { if v == vv { return true } } } } return false } ","date":"2022-02-10","objectID":"/posts/go/%E5%8A%9B%E6%89%A3%E5%88%B7%E9%A2%98/:0:0","tags":null,"title":"力扣刷题","uri":"/posts/go/%E5%8A%9B%E6%89%A3%E5%88%B7%E9%A2%98/"},{"categories":null,"content":"前言 想把博客作为自己的笔记，用过有道云笔记和onenote，hugo美中不足的地方就是搜索不了笔记，直到后面我发现其实是可以搜索的，搜索方式也是多种多样，主要有3种 elastic lunr algolia 易搭建性 难 简单 中等 收费 自建服务器或者一些提供商（有免费额度） 免费 收费（有免费额度） 搜索速度 快 中等（基于浏览器，每次需要下载所有索引） 快 ","date":"2022-02-09","objectID":"/posts/hugo%E4%BD%BF%E7%94%A8%E6%B7%BB%E5%8A%A0algolia%E6%90%9C%E7%B4%A2/:1:0","tags":null,"title":"Hugo使用添加algolia搜索","uri":"/posts/hugo%E4%BD%BF%E7%94%A8%E6%B7%BB%E5%8A%A0algolia%E6%90%9C%E7%B4%A2/"},{"categories":null,"content":"配置algolia账号 ","date":"2022-02-09","objectID":"/posts/hugo%E4%BD%BF%E7%94%A8%E6%B7%BB%E5%8A%A0algolia%E6%90%9C%E7%B4%A2/:2:0","tags":null,"title":"Hugo使用添加algolia搜索","uri":"/posts/hugo%E4%BD%BF%E7%94%A8%E6%B7%BB%E5%8A%A0algolia%E6%90%9C%E7%B4%A2/"},{"categories":null,"content":"注册账号 官网https://www.algolia.com/ ","date":"2022-02-09","objectID":"/posts/hugo%E4%BD%BF%E7%94%A8%E6%B7%BB%E5%8A%A0algolia%E6%90%9C%E7%B4%A2/:2:1","tags":null,"title":"Hugo使用添加algolia搜索","uri":"/posts/hugo%E4%BD%BF%E7%94%A8%E6%B7%BB%E5%8A%A0algolia%E6%90%9C%E7%B4%A2/"},{"categories":null,"content":"创建应用 记住计划选择free,1w的请求和1w的记录应该是够的 ","date":"2022-02-09","objectID":"/posts/hugo%E4%BD%BF%E7%94%A8%E6%B7%BB%E5%8A%A0algolia%E6%90%9C%E7%B4%A2/:2:2","tags":null,"title":"Hugo使用添加algolia搜索","uri":"/posts/hugo%E4%BD%BF%E7%94%A8%E6%B7%BB%E5%8A%A0algolia%E6%90%9C%E7%B4%A2/"},{"categories":null,"content":"创建索引 ","date":"2022-02-09","objectID":"/posts/hugo%E4%BD%BF%E7%94%A8%E6%B7%BB%E5%8A%A0algolia%E6%90%9C%E7%B4%A2/:2:3","tags":null,"title":"Hugo使用添加algolia搜索","uri":"/posts/hugo%E4%BD%BF%E7%94%A8%E6%B7%BB%E5%8A%A0algolia%E6%90%9C%E7%B4%A2/"},{"categories":null,"content":"获取api key 右上角的用户-\u003esetting api key 其中，Application ID 和 Search-Only API Key 是hugo所需要的 ","date":"2022-02-09","objectID":"/posts/hugo%E4%BD%BF%E7%94%A8%E6%B7%BB%E5%8A%A0algolia%E6%90%9C%E7%B4%A2/:2:4","tags":null,"title":"Hugo使用添加algolia搜索","uri":"/posts/hugo%E4%BD%BF%E7%94%A8%E6%B7%BB%E5%8A%A0algolia%E6%90%9C%E7%B4%A2/"},{"categories":null,"content":"配置hugo 我是用的是loveIt主题，在这个主题的配置文件中有配置搜索这个选项 # 搜索配置 [params.search] enable = true # 搜索引擎的类型 (\"lunr\", \"algolia\") type = \"algolia\" # 文章内容最长索引长度 contentLength = 4000 # 搜索框的占位提示语 placeholder = \"\" # 最大结果数目 maxResultLength = 10 # 结果内容片段长度 snippetLength = 50 # 搜索结果中高亮部分的 HTML 标签 highlightTag = \"em\" # 是否在搜索索引中使用基于 baseURL 的绝对路径 absoluteURL = false [params.search.algolia] index = \"blog\" appID = \"xxx\" searchKey = \"xxx\" 其中appID和searchKey是上一步提到的 ","date":"2022-02-09","objectID":"/posts/hugo%E4%BD%BF%E7%94%A8%E6%B7%BB%E5%8A%A0algolia%E6%90%9C%E7%B4%A2/:3:0","tags":null,"title":"Hugo使用添加algolia搜索","uri":"/posts/hugo%E4%BD%BF%E7%94%A8%E6%B7%BB%E5%8A%A0algolia%E6%90%9C%E7%B4%A2/"},{"categories":null,"content":"索引的上传 至此，你的hugo已经可以使用algolia搜索了，但是还有一个问题，就是algolia并没有数据，即索引，我们需要生成索引，并上传给algolia，告诉他我们有哪些文章内容。 ","date":"2022-02-09","objectID":"/posts/hugo%E4%BD%BF%E7%94%A8%E6%B7%BB%E5%8A%A0algolia%E6%90%9C%E7%B4%A2/:4:0","tags":null,"title":"Hugo使用添加algolia搜索","uri":"/posts/hugo%E4%BD%BF%E7%94%A8%E6%B7%BB%E5%8A%A0algolia%E6%90%9C%E7%B4%A2/"},{"categories":null,"content":"非自动方式（不推荐） 运行hugo后，在public文件夹下面会生成一个index.json文件，这个即是索引文件，打开algolia网站，上传即可 ","date":"2022-02-09","objectID":"/posts/hugo%E4%BD%BF%E7%94%A8%E6%B7%BB%E5%8A%A0algolia%E6%90%9C%E7%B4%A2/:4:1","tags":null,"title":"Hugo使用添加algolia搜索","uri":"/posts/hugo%E4%BD%BF%E7%94%A8%E6%B7%BB%E5%8A%A0algolia%E6%90%9C%E7%B4%A2/"},{"categories":null,"content":"自动方式（推荐） github上面有个npm包，用来自动上传索引https://github.com/chrisdmacrae/atomic-algolia使用这个包即可 在你的根目录下新建package.json文件写入如下 { \"scripts\": { \"algolia\": \"atomic-algolia\" } } 添加github action文件到.github\\workclows name:GitHub Pageson:push:branches:- main # Set a branch name to trigger deploymentpull_request:jobs:deploy:runs-on:ubuntu-20.04concurrency:group:${{ github.workflow }}-${{ github.ref }}steps:- uses:actions/checkout@v2with:submodules:true# Fetch Hugo themes (true OR recursive)fetch-depth:0# Fetch all history for .GitInfo and .Lastmod- name:Setup Hugouses:peaceiris/actions-hugo@v2with:hugo-version:'0.85.0'- name:Buildrun:hugo --minify- name:Use Node.jsuses:actions/setup-node@v1with:node-version:'12.x'- name:Install automic-algoliarun:| npm install atomic-algolianpm run algoliaenv:ALGOLIA_APP_ID:${{ secrets.ALGOLIA_APP_ID }}ALGOLIA_ADMIN_KEY:${{ secrets.ALGOLIA_ADMIN_KEY }}ALGOLIA_INDEX_NAME:${{ secrets.ALGOLIA_INDEX_NAME }}ALGOLIA_INDEX_FILE:\"./public/index.json\"添加action的secrcts git push即可 ","date":"2022-02-09","objectID":"/posts/hugo%E4%BD%BF%E7%94%A8%E6%B7%BB%E5%8A%A0algolia%E6%90%9C%E7%B4%A2/:4:2","tags":null,"title":"Hugo使用添加algolia搜索","uri":"/posts/hugo%E4%BD%BF%E7%94%A8%E6%B7%BB%E5%8A%A0algolia%E6%90%9C%E7%B4%A2/"},{"categories":null,"content":"检验 所有配置好后，在站点右上有个搜索图标，点击搜索查看结果 响应速度还是非常快的 ","date":"2022-02-09","objectID":"/posts/hugo%E4%BD%BF%E7%94%A8%E6%B7%BB%E5%8A%A0algolia%E6%90%9C%E7%B4%A2/:5:0","tags":null,"title":"Hugo使用添加algolia搜索","uri":"/posts/hugo%E4%BD%BF%E7%94%A8%E6%B7%BB%E5%8A%A0algolia%E6%90%9C%E7%B4%A2/"},{"categories":null,"content":"实际上，刷机子的原理无非过一会儿发一个包看看能开通不，为了便携且贯彻落实白嫖精神，我使用的是railway部署的，一个免费的PaaS平台https://railway.app,每月有5美元免费额度 ","date":"2022-02-07","objectID":"/posts/cloud/%E7%94%B2%E9%AA%A8%E6%96%87%E4%BA%91%E8%87%AA%E5%8A%A8%E5%88%B7arm/:0:0","tags":["白嫖","cloud"],"title":"甲骨文云自动刷arm(使用railway.app)","uri":"/posts/cloud/%E7%94%B2%E9%AA%A8%E6%96%87%E4%BA%91%E8%87%AA%E5%8A%A8%E5%88%B7arm/"},{"categories":null,"content":"Github地址 https://github.com/lemoex/oci-help ","date":"2022-02-07","objectID":"/posts/cloud/%E7%94%B2%E9%AA%A8%E6%96%87%E4%BA%91%E8%87%AA%E5%8A%A8%E5%88%B7arm/:1:0","tags":["白嫖","cloud"],"title":"甲骨文云自动刷arm(使用railway.app)","uri":"/posts/cloud/%E7%94%B2%E9%AA%A8%E6%96%87%E4%BA%91%E8%87%AA%E5%8A%A8%E5%88%B7arm/"},{"categories":null,"content":"部署至railway ","date":"2022-02-07","objectID":"/posts/cloud/%E7%94%B2%E9%AA%A8%E6%96%87%E4%BA%91%E8%87%AA%E5%8A%A8%E5%88%B7arm/:2:0","tags":["白嫖","cloud"],"title":"甲骨文云自动刷arm(使用railway.app)","uri":"/posts/cloud/%E7%94%B2%E9%AA%A8%E6%96%87%E4%BA%91%E8%87%AA%E5%8A%A8%E5%88%B7arm/"},{"categories":null,"content":"建立自己的git仓库 按照网址上的教程配置好oci-help.ini和pem密钥 然后把源码clone下来，把.ini和pem都考进去 再添加个文件，Dockerfile FROMgolang:1.17.6 as builderENV GO111MODULE=on # CGO_ENABLED alpine禁用cgoWORKDIR/appADD go.mod .ADD go.sum .RUN go mod downloadCOPY . .RUN go build -o app ./RUN mkdir publish \u0026\u0026 cp app publishFROMalpineRUN apk add gcompatWORKDIR/app#复制成品到导出镜像COPY --from=builder /app/publish .#COPY --from=builder /app/*.ini ./COPY --from=builder /app/*.pem ./COPY --from=builder /app/1.sh ./ENTRYPOINT [\"sh\", 'echo -e \"2\\n1\\n\" | ./app']","date":"2022-02-07","objectID":"/posts/cloud/%E7%94%B2%E9%AA%A8%E6%96%87%E4%BA%91%E8%87%AA%E5%8A%A8%E5%88%B7arm/:2:1","tags":["白嫖","cloud"],"title":"甲骨文云自动刷arm(使用railway.app)","uri":"/posts/cloud/%E7%94%B2%E9%AA%A8%E6%96%87%E4%BA%91%E8%87%AA%E5%8A%A8%E5%88%B7arm/"},{"categories":null,"content":"部署至railway.app 注册好railway账号后，选择你的库，部署即可 预计每个月0.18$,四舍五入不要钱 ","date":"2022-02-07","objectID":"/posts/cloud/%E7%94%B2%E9%AA%A8%E6%96%87%E4%BA%91%E8%87%AA%E5%8A%A8%E5%88%B7arm/:2:2","tags":["白嫖","cloud"],"title":"甲骨文云自动刷arm(使用railway.app)","uri":"/posts/cloud/%E7%94%B2%E9%AA%A8%E6%96%87%E4%BA%91%E8%87%AA%E5%8A%A8%E5%88%B7arm/"},{"categories":null,"content":"效果 ","date":"2022-02-07","objectID":"/posts/cloud/%E7%94%B2%E9%AA%A8%E6%96%87%E4%BA%91%E8%87%AA%E5%8A%A8%E5%88%B7arm/:3:0","tags":["白嫖","cloud"],"title":"甲骨文云自动刷arm(使用railway.app)","uri":"/posts/cloud/%E7%94%B2%E9%AA%A8%E6%96%87%E4%BA%91%E8%87%AA%E5%8A%A8%E5%88%B7arm/"},{"categories":null,"content":"结论 实际上，用自己的虚拟机部署方便的多= =，用这个平台主要是不怕机子boom，没办法，就是爱折腾 ","date":"2022-02-07","objectID":"/posts/cloud/%E7%94%B2%E9%AA%A8%E6%96%87%E4%BA%91%E8%87%AA%E5%8A%A8%E5%88%B7arm/:4:0","tags":["白嫖","cloud"],"title":"甲骨文云自动刷arm(使用railway.app)","uri":"/posts/cloud/%E7%94%B2%E9%AA%A8%E6%96%87%E4%BA%91%E8%87%AA%E5%8A%A8%E5%88%B7arm/"},{"categories":null,"content":"有时候，ddos或者各种攻击会导致服务瘫痪，或者当前服务器进入流量黑洞，无法访问，或者管理员手欠不小心删了一些数据，这时候，数据库的备份就显得尤为重要了。 本案例使用的是腾讯云的cos云存储来备份数据库，数据库在docker中的mysql中，每天备份一次，所以数据不是实时的，可以作为兜底使用 ","date":"2022-02-07","objectID":"/posts/devops/mysql%E8%87%AA%E5%8A%A8%E5%A4%87%E4%BB%BD/:0:0","tags":["devops"],"title":"Mysql自动备份","uri":"/posts/devops/mysql%E8%87%AA%E5%8A%A8%E5%A4%87%E4%BB%BD/"},{"categories":null,"content":"从docker中导出数据库 docker exec mysql bash -c \"mysqldump -uroot -p123456 数据库名\u003e /xxx.sql\" ","date":"2022-02-07","objectID":"/posts/devops/mysql%E8%87%AA%E5%8A%A8%E5%A4%87%E4%BB%BD/:1:0","tags":["devops"],"title":"Mysql自动备份","uri":"/posts/devops/mysql%E8%87%AA%E5%8A%A8%E5%A4%87%E4%BB%BD/"},{"categories":null,"content":"配置腾讯云cos 网址 https://cloud.tencent.com/document/product/436/63143 ","date":"2022-02-07","objectID":"/posts/devops/mysql%E8%87%AA%E5%8A%A8%E5%A4%87%E4%BB%BD/:2:0","tags":["devops"],"title":"Mysql自动备份","uri":"/posts/devops/mysql%E8%87%AA%E5%8A%A8%E5%A4%87%E4%BB%BD/"},{"categories":null,"content":"下载 Linux 版本 COSCLI wget https://github.com/tencentyun/coscli/releases/download/v0.10.2-beta/coscli-linux #运行以下命令重命名文件： mv coscli-linux coscli \u0026\u0026 chmod 755 coscli #命令在其他位置为 COSCLI 交互式地生成配置文件 ./coscli config init ~/.cos.yaml cos配置文件 ","date":"2022-02-07","objectID":"/posts/devops/mysql%E8%87%AA%E5%8A%A8%E5%A4%87%E4%BB%BD/:2:1","tags":["devops"],"title":"Mysql自动备份","uri":"/posts/devops/mysql%E8%87%AA%E5%8A%A8%E5%A4%87%E4%BB%BD/"},{"categories":null,"content":"数据库备份脚本 #/bin/bash cd /root/backup #导出数据库 docker exec mysql bash -c \"mysqldump -uroot -p123456 dbname\u003e /dbname.sql\" #cpoy到本机 docker cp mysql:/dbname.sql ./ #删除docker中的文件 docker exec mysql rm /dbname.sql #提交到腾讯云cos fname=$(date \"+%Y-%m-%d-%H-%M-%S\").sql echo \"开始上传数据库$fname\" ./coscli cp ./dbname.sql cos://dbname-backup/$fname rm ./dbname.sql #提醒 #可以使用各种方式提醒，server酱，短信啥的，我用的是自建server酱，wecomchan，详情bing #删除7天前的备份文件 ./coscli rm cos://bucket1/example/ -r --include \"\" 把这个脚本添加到crontab中，每天执行一次,我用的是宝塔的计划任务 ","date":"2022-02-07","objectID":"/posts/devops/mysql%E8%87%AA%E5%8A%A8%E5%A4%87%E4%BB%BD/:3:0","tags":["devops"],"title":"Mysql自动备份","uri":"/posts/devops/mysql%E8%87%AA%E5%8A%A8%E5%A4%87%E4%BB%BD/"},{"categories":null,"content":"运行结果 ","date":"2022-02-07","objectID":"/posts/devops/mysql%E8%87%AA%E5%8A%A8%E5%A4%87%E4%BB%BD/:4:0","tags":["devops"],"title":"Mysql自动备份","uri":"/posts/devops/mysql%E8%87%AA%E5%8A%A8%E5%A4%87%E4%BB%BD/"},{"categories":null,"content":"docker-compose我认为是单机管理容器的最佳方案，如果要多机 ","date":"2022-02-07","objectID":"/posts/devops/docker/:0:0","tags":["devops"],"title":"docker\u0026compose安装","uri":"/posts/devops/docker/"},{"categories":null,"content":"docker安装 curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun ","date":"2022-02-07","objectID":"/posts/devops/docker/:1:0","tags":["devops"],"title":"docker\u0026compose安装","uri":"/posts/devops/docker/"},{"categories":null,"content":"换源 cat \u003e /etc/docker/daemon.json \u003c\u003ceof { \"registry-mirrors\": [\"https://jrromknz.mirror.aliyuncs.com\"], \"exec-opts\":[\"native.cgroupdriver=systemd\"] } eof systemctl enable docker.service systemctl daemon-reload systemctl restart docker.service ","date":"2022-02-07","objectID":"/posts/devops/docker/:2:0","tags":["devops"],"title":"docker\u0026compose安装","uri":"/posts/devops/docker/"},{"categories":null,"content":"compose安装(x86) curl -L \"https://github.com/docker/compose/releases/download/v2.2.3/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose chmod +x /usr/local/bin/docker-compose # 加速版 curl -L \"https://hub.fastgit.xyz/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose chmod +x /usr/local/bin/docker-compose ","date":"2022-02-07","objectID":"/posts/devops/docker/:3:0","tags":["devops"],"title":"docker\u0026compose安装","uri":"/posts/devops/docker/"},{"categories":null,"content":"compose arm 版本 wget https://github.com/docker/compose/releases/download/v2.2.3/docker-compose-linux-armv7 mv ./docker-compose-linux-armv7 /usr/local/bin/docker-compose chmod +x /usr/local/bin/docker-compose ","date":"2022-02-07","objectID":"/posts/devops/docker/:4:0","tags":["devops"],"title":"docker\u0026compose安装","uri":"/posts/devops/docker/"},{"categories":null,"content":"简介 男，01年双鱼座，对golang，devops感兴趣 擅长语言：Golang、Python、Javascript 常用昵称：lyj0309 Github：https://github.com/lyj0309 常用网站 代码启示录 github ","date":"2022-02-07","objectID":"/about/:0:0","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"fly.io 类似于Okteto、Heroku和Railway的PaaS平台。 只能通过CLI登录，对小白可能有些不太友好。 官网：fly.io 免费额度：Fly App Pricing 免费额度有三个不间断运行的容器，以及160G的出站流量。(东亚30g，欧美100g，印度30g) ","date":"2022-02-07","objectID":"/posts/cloud/fly/:1:0","tags":["白嫖","cloud","PaaS"],"title":"Fly.io 免费PaaS平台，以及哪吒面板的部署","uri":"/posts/cloud/fly/"},{"categories":null,"content":"使用(以部署哪吒面板为例) 安装fly cli 把哪吒源码下下来，需要进行一些修改 修改cmd/dashboad/main.go ,在init函数下加上 //新建conf文件 file6, err := os.Create(\"data/config.yaml\") if err != nil { fmt.Println(err) } data := `debug: false httpport: 80 grpcport: 5555 oauth2: type: \"github\" #Oauth2 登录接入类型，gitee/github admin: \"{你的github用户名}\" #管理员列表，半角逗号隔开 clientid: \"\" # 在 https://github.com/settings/developers 创建，无需审核 Callback 填 http(s)://域名或IP/oauth2/callback clientsecret: \"\" site: brand: \"xxx\" cookiename: \"nezha-dashboard\" #浏览器 Cookie 字段名，可不改 theme: \"default\" ` file6.WriteString(data) file6.Close() 这样就相当于可以直接嵌入文件 为了使数据持久话，我们需要添加volume,fly提供3g免费空间，我们新建一个g就行，fly volumes create nz_data --region hkg --size 1 运行fly launch 生成fly.toml文件，修改成 # fly.toml file generated for nz on 2022-02-07T02:08:50+08:00 app = \"nz\" kill_signal = \"SIGINT\" kill_timeout = 5 processes = [] [env] [experimental] allowed_public_ports = [] auto_rollback = true [mounts] destination = \"/dashboard/data\" source = \"nz_data\" [[services]] http_checks = [] internal_port = 80 processes = [\"app\"] protocol = \"tcp\" script_checks = [] [services.concurrency] hard_limit = 25 soft_limit = 20 type = \"connections\" [[services.ports]] handlers = [\"http\"] port = 80 [[services.ports]] handlers = [\"tls\", \"http\"] port = 443 [[services.tcp_checks]] grace_period = \"1s\" interval = \"15s\" restart_limit = 0 timeout = \"2s\" [[services]] http_checks = [] internal_port = 5555 processes = [\"app\"] protocol = \"tcp\" script_checks = [] [services.concurrency] hard_limit = 25 soft_limit = 20 type = \"connections\" [[services.ports]] port = 5555 [[services.tcp_checks]] grace_period = \"1s\" interval = \"15s\" restart_limit = 0 timeout = \"2s\" 具体意思可以去fly文档看，文档还是非常详细的 运行fly deploy部署app，他会自动把你代码打包成docker镜像上传 大功告成，接下来你就可以去控制台看部署的结果了 演示站 ","date":"2022-02-07","objectID":"/posts/cloud/fly/:2:0","tags":["白嫖","cloud","PaaS"],"title":"Fly.io 免费PaaS平台，以及哪吒面板的部署","uri":"/posts/cloud/fly/"},{"categories":null,"content":"优点 不怕宕机 白嫖党狂喜 ","date":"2022-02-07","objectID":"/posts/cloud/fly/:2:1","tags":["白嫖","cloud","PaaS"],"title":"Fly.io 免费PaaS平台，以及哪吒面板的部署","uri":"/posts/cloud/fly/"},{"categories":null,"content":"缺点 很难更新 备份或者迁移很难 ","date":"2022-02-07","objectID":"/posts/cloud/fly/:2:2","tags":["白嫖","cloud","PaaS"],"title":"Fly.io 免费PaaS平台，以及哪吒面板的部署","uri":"/posts/cloud/fly/"},{"categories":null,"content":"后记 fly.io 也是我最近才刚刚发现的，不知道能不能长久，也不知道有没有大厂背书。所以稳定性还有待观察 注册fly是要用信用卡的，一般的卡都能过，会交易10美元，所以卡里面最好大于10美元，啥卡都行，没卡的去微信搞个易呗卡 虽说是部署在香港的，但是ipv4解析到的地方是英国，所以访问速度不是很快，ipv6解到的是新加坡 ","date":"2022-02-07","objectID":"/posts/cloud/fly/:3:0","tags":["白嫖","cloud","PaaS"],"title":"Fly.io 免费PaaS平台，以及哪吒面板的部署","uri":"/posts/cloud/fly/"},{"categories":null,"content":"参考文献 https://liusy.eu.org/tag/fly-io/ https://dnslin.com/index.php/archives/37.html https://blog.kermsite.com/p/flyio/ ","date":"2022-02-07","objectID":"/posts/cloud/fly/:4:0","tags":["白嫖","cloud","PaaS"],"title":"Fly.io 免费PaaS平台，以及哪吒面板的部署","uri":"/posts/cloud/fly/"},{"categories":null,"content":"安装 #deb curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.15.2-amd64.deb sudo dpkg -i filebeat-7.15.2-amd64.deb #rpm curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.15.2-x86_64.rpm sudo rpm -vi filebeat-7.15.2-x86_64.rpm ","date":"2021-10-21","objectID":"/posts/middleware/elastic/filebeat/:1:0","tags":["devops","elastic"],"title":"filebeat","uri":"/posts/middleware/elastic/filebeat/"},{"categories":null,"content":"设置 路径： /var/filebeat/filebeat.yml output.elasticsearch:hosts:[\"myEShost:9200\"]username:\"filebeat_internal\"password:\"YOUR_PASSWORD\"setup.kibana:host:\"mykibanahost:5601\"username:\"my_kibana_user\"password:\"{pwd}\"","date":"2021-10-21","objectID":"/posts/middleware/elastic/filebeat/:2:0","tags":["devops","elastic"],"title":"filebeat","uri":"/posts/middleware/elastic/filebeat/"},{"categories":null,"content":"模块配置 可用模块 filebeat modules list 开启模块 filebeat modules enable system nginx mysql 模块设置路径 ： /var/filebeat/modules.d/ ","date":"2021-10-21","objectID":"/posts/middleware/elastic/filebeat/:3:0","tags":["devops","elastic"],"title":"filebeat","uri":"/posts/middleware/elastic/filebeat/"},{"categories":null,"content":"启动 验证服务 filebeat setup -e 验证完可用后，后台启动 sudo service filebeat start ","date":"2021-10-21","objectID":"/posts/middleware/elastic/filebeat/:4:0","tags":["devops","elastic"],"title":"filebeat","uri":"/posts/middleware/elastic/filebeat/"},{"categories":null,"content":"GOVER=1.17.2 wget golang.google.cn/dl/go${GOVER}.linux-amd64.tar.gz tar -xzf go${GOVER}.linux-amd64.tar.gz mv ./go /usr/local/go echo \"export PATH=$PATH:/usr/local/go/bin\" \u003e\u003e /etc/profile source /etc/profile rm golang.google.cn/dl/go${GOVER}.linux-amd64.tar.gz #腾讯外网 go env -w GOPROXY=https://mirrors.cloud.tencent.com/go/ #腾讯内网 go env -w GOPROXY=http://mirrors.tencentyun.com/go/ #七牛镜像 go env -w GOPROXY=https://goproxy.cn,direct export GOPROXY=http://mirrors.tencentyun.com/go/ ","date":"2021-10-21","objectID":"/posts/go/%E5%AE%89%E8%A3%85/:0:0","tags":["Go"],"title":"go安装","uri":"/posts/go/%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"go提供了一个http包，可以通过这个包方便的进行http请求 import ( \"fmt\" \"io/ioutil\" \"net/http\" \"strings\" ) // http.Get func httpGet() { resp, err := http.Get(\"http://www.baidu.com\") if err != nil { fmt.Println(err) return } defer resp.Body.Close() body, err := ioutil.ReadAll(resp.Body) fmt.Println(string(body)) } func httpPost() { resp, err := http.Post(\"http://www.baidu.com\", \"application/x-www-form-urlencode\", strings.NewReader(\"name=abc\")) // Content-Type post请求必须设置 if err != nil { return } defer resp.Body.Close() body, err := ioutil.ReadAll(resp.Body) fmt.Println(string(body)) } client := \u0026http.Client{} req, err := http.NewRequest(\"POST\", \"http://121.36.71.167:7001/\", strings.NewReader(\"name=cjb\")) if err != nil { fmt.Println(err) } req.Header.Set(\"Content-Type\", \"application/json\") req.Header.Set(\"Cookie\", \"name=anny\") resp, err := client.Do(req) if err != nil { fmt.Println(err) } defer resp.Body.Close() body, err := ioutil.ReadAll(resp.Body) if err != nil { fmt.Println(err) } fmt.Println(string(body)) ","date":"2021-10-21","objectID":"/posts/go/%E8%AF%B7%E6%B1%82-http/:0:0","tags":["Go"],"title":"go请求http","uri":"/posts/go/%E8%AF%B7%E6%B1%82-http/"},{"categories":null,"content":"概述 fetch()的功能与 XMLHttpRequest 基本相同，但有三个主要的差异。 （1）fetch()使用 Promise，不使用回调函数，因此大大简化了写法，写起来更简洁。 （2）fetch()采用模块化设计，API 分散在多个对象上（Response 对象、Request 对象、Headers 对象），更合理一些；相比之下，XMLHttpRequest 的 API 设计并不是很好，输入、输出、状态都在同一个接口管理，容易写出非常混乱的代码。 （3）fetch()通过数据流（Stream 对象）处理数据，可以分块读取，有利于提高网站性能表现，减少内存占用，对于请求大文件或者网速慢的场景相当有用。XMLHTTPRequest 对象不支持数据流，所有的数据必须放在缓存里，不支持分块读取，必须等待全部拿到后，再一次性吐出来。 在用法上，fetch()接受一个 URL 字符串作为参数，默认向该网址发出 GET 请求，返回一个 Promise 对象。它的基本用法如下。 fetch(url) .then(...) .catch(...) 下面是一个例子，从服务器获取 JSON 数据。 fetch('https://api.github.com/users/ruanyf') .then(response =\u003e response.json()) .then(json =\u003e console.log(json)) .catch(err =\u003e console.log('Request Failed', err)); async function fetchText() { let response = await fetch('/readme.txt'); console.log(response.status); console.log(response.statusText); } ","date":"2021-10-21","objectID":"/posts/front/fetch/:1:0","tags":["前端"],"title":"webApi fetch使用","uri":"/posts/front/fetch/"},{"categories":null,"content":"2.3 Response.headers 属性 Response 对象还有一个Response.headers属性，指向一个 Headers 对象，对应 HTTP 回应的所有标头。 Headers 对象可以使用for…of循环进行遍历。 ","date":"2021-10-21","objectID":"/posts/front/fetch/:1:1","tags":["前端"],"title":"webApi fetch使用","uri":"/posts/front/fetch/"},{"categories":null,"content":"2.4 读取内容的方法 Response对象根据服务器返回的不同类型的数据，提供了不同的读取方法。 response.text()：得到文本字符串。response.json()：得到 JSON 对象。response.blob()：得到二进制 Blob 对象。response.formData()：得到 FormData 表单对象。response.arrayBuffer()：得到二进制 ArrayBuffer 对象。 上面5个读取方法都是异步的，返回的都是 Promise 对象。必须等到异步操作结束，才能得到服务器返回的完整数据。 response.text()可以用于获取文本数据，比如 HTML 文件。 response.json()直接解析json response.formData()主要用在 Service Worker 里面，拦截用户提交的表单，修改某些数据以后，再提交给服务器。 response.blob()用于获取二进制文件。 const response = await fetch('flower.jpg'); const myBlob = await response.blob(); const objectURL = URL.createObjectURL(myBlob); const myImage = document.querySelector('img'); myImage.src = objectURL; 上面示例读取图片文件flower.jpg，显示在网页上。 ","date":"2021-10-21","objectID":"/posts/front/fetch/:1:2","tags":["前端"],"title":"webApi fetch使用","uri":"/posts/front/fetch/"},{"categories":null,"content":"POST 请求 const response = await fetch(url, { method: 'POST', headers: { \"Content-type\": \"application/x-www-form-urlencoded; charset=UTF-8\", }, body: 'foo=bar\u0026lorem=ipsum', }); const json = await response.json(); const user = { name: 'John', surname: 'Smith' }; const response = await fetch('/article/fetch/post/user', { method: 'POST', headers: { 'Content-Type': 'application/json;charset=utf-8' }, body: JSON.stringify(user) }); 上面示例中，配置对象用到了三个属性。 method：HTTP 请求的方法，POST、DELETE、PUT都在这个属性设置。headers：一个对象，用来定制 HTTP 请求的标头。body：POST 请求的数据体。 注意，有些标头不能通过headers属性设置，比如Content-Length、Cookie、Host等等。它们是由浏览器自动生成，无法修改。 ","date":"2021-10-21","objectID":"/posts/front/fetch/:2:0","tags":["前端"],"title":"webApi fetch使用","uri":"/posts/front/fetch/"},{"categories":null,"content":"（4）文件上传 如果表单里面有文件选择器，可以用前一个例子的写法，上传的文件包含在整个表单里面，一起提交。 另一种方法是用脚本添加文件，构造出一个表单，进行上传，请看下面的例子。 const input = document.querySelector('input[type=\"file\"]'); const data = new FormData(); data.append('file', input.files[0]); data.append('user', 'foo'); fetch('/avatars', { method: 'POST', body: data }); 上传二进制文件时，不用修改标头的Content-Type，浏览器会自动设置。 ","date":"2021-10-21","objectID":"/posts/front/fetch/:2:1","tags":["前端"],"title":"webApi fetch使用","uri":"/posts/front/fetch/"},{"categories":null,"content":"（5）直接上传二进制数据 fetch()也可以直接上传二进制数据，将 Blob 或 arrayBuffer 数据放在body属性里面。 let blob = await new Promise(resolve =\u003e canvasElem.toBlob(resolve, 'image/png') ); let response = await fetch('/article/fetch/post/image', { method: 'POST', body: blob }); ```js ","date":"2021-10-21","objectID":"/posts/front/fetch/:2:2","tags":["前端"],"title":"webApi fetch使用","uri":"/posts/front/fetch/"},{"categories":null,"content":"基本原理和配置 wireguard会新建一张虚拟网卡，所有的流量都经过这个网卡，所以你要设定的主要有3块东西 服务器公网地址 v6 || v4 服务端网段 \u0026\u0026 ip 客户端网段 \u0026\u0026 ip ","date":"2021-10-21","objectID":"/posts/linux/wireguard/:0:1","tags":null,"title":"wireguard安装","uri":"/posts/linux/wireguard/"},{"categories":null,"content":"安装脚本 curl -O https://raw.githubusercontent.com/angristan/wireguard-install/master/wireguard-install.sh chmod +x wireguard-install.sh ./wireguard-install.sh # 国内版 curl -O https://raw.fastgit.org/angristan/wireguard-install/master/wireguard-install.sh chmod +x wireguard-install.sh ./wireguard-install.sh ","date":"2021-10-21","objectID":"/posts/linux/wireguard/:0:2","tags":null,"title":"wireguard安装","uri":"/posts/linux/wireguard/"},{"categories":null,"content":"一、gitmodules是什么 子模块允许你将一个 Git 仓库作为另一个 Git 仓库的子目录。 它能让你将另一个仓库克隆到自己的项目中，同时还保持提交的独立。 ","date":"2021-09-21","objectID":"/posts/gitmodules%E8%AF%A6%E8%A7%A3git%E5%AD%90%E6%A8%A1%E5%9D%97%E9%85%8D%E7%BD%AE/:1:0","tags":["git","code"],"title":"gitmodules详解（Git子模块配置）","uri":"/posts/gitmodules%E8%AF%A6%E8%A7%A3git%E5%AD%90%E6%A8%A1%E5%9D%97%E9%85%8D%E7%BD%AE/"},{"categories":null,"content":"如何使用 $ git submodule add https://github.com/XXX .gitmodules文件 [submodule \"themes/ananke\"] path = themes/ananke url = https://github.com/theNewDynamic/gohugo-theme-ananke.git [submodule \"themes/even\"] path = themes/even url = https://github.com/olOwOlo/hugo-theme-even.git ","date":"2021-09-21","objectID":"/posts/gitmodules%E8%AF%A6%E8%A7%A3git%E5%AD%90%E6%A8%A1%E5%9D%97%E9%85%8D%E7%BD%AE/:2:0","tags":["git","code"],"title":"gitmodules详解（Git子模块配置）","uri":"/posts/gitmodules%E8%AF%A6%E8%A7%A3git%E5%AD%90%E6%A8%A1%E5%9D%97%E9%85%8D%E7%BD%AE/"},{"categories":["life"],"content":"1.安装浏览器 点击下载 下载完成后安装 ","date":"2021-09-21","objectID":"/posts/%E5%AD%A6%E4%B9%A0%E9%80%9A%E8%84%9A%E6%9C%AC%E5%AE%89%E8%A3%85%E6%89%8B%E6%9C%BA%E7%89%88/:1:0","tags":["学习通"],"title":"学习通脚本安装（手机版）","uri":"/posts/%E5%AD%A6%E4%B9%A0%E9%80%9A%E8%84%9A%E6%9C%AC%E5%AE%89%E8%A3%85%E6%89%8B%E6%9C%BA%E7%89%88/"},{"categories":["life"],"content":"2.安装油猴 打开浏览器，跟图走 ","date":"2021-09-21","objectID":"/posts/%E5%AD%A6%E4%B9%A0%E9%80%9A%E8%84%9A%E6%9C%AC%E5%AE%89%E8%A3%85%E6%89%8B%E6%9C%BA%E7%89%88/:2:0","tags":["学习通"],"title":"学习通脚本安装（手机版）","uri":"/posts/%E5%AD%A6%E4%B9%A0%E9%80%9A%E8%84%9A%E6%9C%AC%E5%AE%89%E8%A3%85%E6%89%8B%E6%9C%BA%E7%89%88/"},{"categories":["life"],"content":"3.安装脚本 在此浏览器内打开 http://ti.fakev.cn/scripts 点击安装脚本 ","date":"2021-09-21","objectID":"/posts/%E5%AD%A6%E4%B9%A0%E9%80%9A%E8%84%9A%E6%9C%AC%E5%AE%89%E8%A3%85%E6%89%8B%E6%9C%BA%E7%89%88/:3:0","tags":["学习通"],"title":"学习通脚本安装（手机版）","uri":"/posts/%E5%AD%A6%E4%B9%A0%E9%80%9A%E8%84%9A%E6%9C%AC%E5%AE%89%E8%A3%85%E6%89%8B%E6%9C%BA%E7%89%88/"},{"categories":["life"],"content":"4.检查安装 打开 http://chaoxing.com 登录 打开一个课程，如果出现查题面板即安装成功 ","date":"2021-09-21","objectID":"/posts/%E5%AD%A6%E4%B9%A0%E9%80%9A%E8%84%9A%E6%9C%AC%E5%AE%89%E8%A3%85%E6%89%8B%E6%9C%BA%E7%89%88/:4:0","tags":["学习通"],"title":"学习通脚本安装（手机版）","uri":"/posts/%E5%AD%A6%E4%B9%A0%E9%80%9A%E8%84%9A%E6%9C%AC%E5%AE%89%E8%A3%85%E6%89%8B%E6%9C%BA%E7%89%88/"},{"categories":["life"],"content":"一、浏览器选择 推荐使用edge，如果是chrome要科网 ","date":"2021-09-21","objectID":"/posts/%E5%AD%A6%E4%B9%A0%E9%80%9A%E8%84%9A%E6%9C%AC%E5%AE%89%E8%A3%85%E7%94%B5%E8%84%91%E7%89%88/:1:0","tags":["学习通"],"title":"学习通脚本安装（电脑版）","uri":"/posts/%E5%AD%A6%E4%B9%A0%E9%80%9A%E8%84%9A%E6%9C%AC%E5%AE%89%E8%A3%85%E7%94%B5%E8%84%91%E7%89%88/"},{"categories":["life"],"content":"二、安装油猴 打开 https://microsoftedge.microsoft.com/addons/detail/iikmkjmpaadaobahmlepeloendndfphd?hl=zh-CN（edge） https://chrome.google.com/webstore/detail/tampermonkey/dhdgffkkebhmkfjojejmpbldmpobfkfo?hl=zh-CN (chrome) 点击安装拓展 ","date":"2021-09-21","objectID":"/posts/%E5%AD%A6%E4%B9%A0%E9%80%9A%E8%84%9A%E6%9C%AC%E5%AE%89%E8%A3%85%E7%94%B5%E8%84%91%E7%89%88/:2:0","tags":["学习通"],"title":"学习通脚本安装（电脑版）","uri":"/posts/%E5%AD%A6%E4%B9%A0%E9%80%9A%E8%84%9A%E6%9C%AC%E5%AE%89%E8%A3%85%E7%94%B5%E8%84%91%E7%89%88/"},{"categories":["life"],"content":"三、安装脚本 打开 http://ti.fakev.cn/script 点击安装脚本 ","date":"2021-09-21","objectID":"/posts/%E5%AD%A6%E4%B9%A0%E9%80%9A%E8%84%9A%E6%9C%AC%E5%AE%89%E8%A3%85%E7%94%B5%E8%84%91%E7%89%88/:3:0","tags":["学习通"],"title":"学习通脚本安装（电脑版）","uri":"/posts/%E5%AD%A6%E4%B9%A0%E9%80%9A%E8%84%9A%E6%9C%AC%E5%AE%89%E8%A3%85%E7%94%B5%E8%84%91%E7%89%88/"},{"categories":["life"],"content":"四、检查安装 打开油猴管理面板，确保当前只有一个网课脚本打开 随便打开一个课程，记得要打开《学生学习页面》像https://mooc1-1.chaoxing.com/mycourse/studentstudy这样，脚本会自动启动，遇到题目会自动答题，遇到视频会自动播放 视频可以开倍速拉进度条，不过不建议， ","date":"2021-09-21","objectID":"/posts/%E5%AD%A6%E4%B9%A0%E9%80%9A%E8%84%9A%E6%9C%AC%E5%AE%89%E8%A3%85%E7%94%B5%E8%84%91%E7%89%88/:4:0","tags":["学习通"],"title":"学习通脚本安装（电脑版）","uri":"/posts/%E5%AD%A6%E4%B9%A0%E9%80%9A%E8%84%9A%E6%9C%AC%E5%AE%89%E8%A3%85%E7%94%B5%E8%84%91%E7%89%88/"}]